{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRIO5201A - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importer le fichier \"network.py\"\n",
    "import network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On importe les données du MNIST\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After loading the MNIST data, we'll set up a Network with 30 hidden neurons.\n",
    "#We do this after importing the Python program listed above, which is named network.\n",
    "net = network.Network([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9099 / 10000\n",
      "Epoch 1: 9271 / 10000\n",
      "Epoch 2: 9338 / 10000\n",
      "Epoch 3: 9369 / 10000\n",
      "Epoch 4: 9327 / 10000\n",
      "Epoch 5: 9393 / 10000\n",
      "Epoch 6: 9427 / 10000\n",
      "Epoch 7: 9432 / 10000\n",
      "Epoch 8: 9455 / 10000\n",
      "Epoch 9: 9462 / 10000\n",
      "Epoch 10: 9457 / 10000\n",
      "Epoch 11: 9470 / 10000\n",
      "Epoch 12: 9460 / 10000\n",
      "Epoch 13: 9453 / 10000\n",
      "Epoch 14: 9450 / 10000\n",
      "Epoch 15: 9475 / 10000\n",
      "Epoch 16: 9490 / 10000\n",
      "Epoch 17: 9460 / 10000\n",
      "Epoch 18: 9475 / 10000\n",
      "Epoch 19: 9492 / 10000\n",
      "Epoch 20: 9502 / 10000\n",
      "Epoch 21: 9476 / 10000\n",
      "Epoch 22: 9480 / 10000\n",
      "Epoch 23: 9482 / 10000\n",
      "Epoch 24: 9488 / 10000\n",
      "Epoch 25: 9483 / 10000\n",
      "Epoch 26: 9471 / 10000\n",
      "Epoch 27: 9492 / 10000\n",
      "Epoch 28: 9485 / 10000\n",
      "Epoch 29: 9490 / 10000\n"
     ]
    }
   ],
   "source": [
    "#Finally, we'll use stochastic gradient descent to learn from the MNIST training_data over 30 epochs,\n",
    "#with a mini-batch size of 10, and a learning rate of η=3.0η=3.0\n",
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 4686 / 10000\n",
      "Epoch 1: 4865 / 10000\n",
      "Epoch 2: 5640 / 10000\n",
      "Epoch 3: 5618 / 10000\n",
      "Epoch 4: 6572 / 10000\n",
      "Epoch 5: 6615 / 10000\n",
      "Epoch 6: 6670 / 10000\n",
      "Epoch 7: 7539 / 10000\n",
      "Epoch 8: 7570 / 10000\n",
      "Epoch 9: 7579 / 10000\n",
      "Epoch 10: 7608 / 10000\n",
      "Epoch 11: 7597 / 10000\n",
      "Epoch 12: 7615 / 10000\n",
      "Epoch 13: 7618 / 10000\n",
      "Epoch 14: 7627 / 10000\n",
      "Epoch 15: 7612 / 10000\n",
      "Epoch 16: 7624 / 10000\n",
      "Epoch 17: 7622 / 10000\n",
      "Epoch 18: 7623 / 10000\n",
      "Epoch 19: 7642 / 10000\n",
      "Epoch 20: 7645 / 10000\n",
      "Epoch 21: 7641 / 10000\n",
      "Epoch 22: 7641 / 10000\n",
      "Epoch 23: 7649 / 10000\n",
      "Epoch 24: 7650 / 10000\n",
      "Epoch 25: 7648 / 10000\n",
      "Epoch 26: 7644 / 10000\n",
      "Epoch 27: 7637 / 10000\n",
      "Epoch 28: 7647 / 10000\n",
      "Epoch 29: 7658 / 10000\n"
     ]
    }
   ],
   "source": [
    "#Let's rerun the above experiment, changing the number of hidden neurons to 100.\n",
    "#As was the case earlier, if you're running the code as you read along,\n",
    "#you should be warned that it takes quite a while to execute\n",
    "#(on my machine this experiment takes tens of seconds for each training epoch),\n",
    "#so it's wise to continue reading in parallel while the code executes.\n",
    "\n",
    "net = network.Network([784, 100, 10])\n",
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, this improves the results to 96.59 percent. At least in this case, using more hidden neurons helps us get better results.Reader feedback indicates quite some variation in results for this experiment, and some training runs give results quite a bit worse. Using the techniques introduced in chapter 3 will greatly reduce the variation in performance across different training runs for our networks..\n",
    "\n",
    "Of course, to obtain these accuracies I had to make specific choices for the number of epochs of training, the mini-batch size, and the learning rate, ηη. As I mentioned above, these are known as hyper-parameters for our neural network, in order to distinguish them from the parameters (weights and biases) learnt by our learning algorithm. If we choose our hyper-parameters poorly, we can get bad results. Suppose, for example, that we'd chosen the learning rate to be η=0.001η=0.001,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 988 / 10000\n",
      "Epoch 1: 998 / 10000\n",
      "Epoch 2: 1071 / 10000\n",
      "Epoch 3: 1127 / 10000\n",
      "Epoch 4: 1151 / 10000\n",
      "Epoch 5: 1197 / 10000\n",
      "Epoch 6: 1237 / 10000\n",
      "Epoch 7: 1289 / 10000\n",
      "Epoch 8: 1339 / 10000\n",
      "Epoch 9: 1379 / 10000\n",
      "Epoch 10: 1414 / 10000\n",
      "Epoch 11: 1438 / 10000\n",
      "Epoch 12: 1475 / 10000\n",
      "Epoch 13: 1519 / 10000\n",
      "Epoch 14: 1572 / 10000\n",
      "Epoch 15: 1619 / 10000\n",
      "Epoch 16: 1655 / 10000\n",
      "Epoch 17: 1698 / 10000\n",
      "Epoch 18: 1734 / 10000\n",
      "Epoch 19: 1780 / 10000\n",
      "Epoch 20: 1820 / 10000\n",
      "Epoch 21: 1853 / 10000\n",
      "Epoch 22: 1894 / 10000\n",
      "Epoch 23: 1956 / 10000\n",
      "Epoch 24: 2008 / 10000\n",
      "Epoch 25: 2042 / 10000\n",
      "Epoch 26: 2076 / 10000\n",
      "Epoch 27: 2118 / 10000\n",
      "Epoch 28: 2162 / 10000\n",
      "Epoch 29: 2194 / 10000\n"
     ]
    }
   ],
   "source": [
    "net = network.Network([784, 100, 10])\n",
    "net.SGD(training_data, 30, 10, 0.001, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9077 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9272 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9373 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9411 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9422 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9458 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9434 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9476 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9438 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9491 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9512 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9488 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9541 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9534 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9498 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9539 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9543 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9510 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9524 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9540 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9519 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9497 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9526 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9517 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9526 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9551 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9526 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9536 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9539 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9077,\n",
       "  9272,\n",
       "  9373,\n",
       "  9411,\n",
       "  9422,\n",
       "  9431,\n",
       "  9458,\n",
       "  9434,\n",
       "  9476,\n",
       "  9438,\n",
       "  9491,\n",
       "  9512,\n",
       "  9488,\n",
       "  9541,\n",
       "  9534,\n",
       "  9498,\n",
       "  9539,\n",
       "  9543,\n",
       "  9510,\n",
       "  9524,\n",
       "  9540,\n",
       "  9519,\n",
       "  9497,\n",
       "  9526,\n",
       "  9517,\n",
       "  9526,\n",
       "  9551,\n",
       "  9526,\n",
       "  9536,\n",
       "  9539],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import network2\n",
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 1.85777569795\n",
      "Accuracy on evaluation data: 5738 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 1.3042378396\n",
      "Accuracy on evaluation data: 6952 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 1.04570121369\n",
      "Accuracy on evaluation data: 7243 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.896191737276\n",
      "Accuracy on evaluation data: 7532 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.730838204236\n",
      "Accuracy on evaluation data: 7751 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.630722935236\n",
      "Accuracy on evaluation data: 7927 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.552494613584\n",
      "Accuracy on evaluation data: 8000 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.472837290136\n",
      "Accuracy on evaluation data: 8046 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.438506237424\n",
      "Accuracy on evaluation data: 8104 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.389185847276\n",
      "Accuracy on evaluation data: 8128 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.331603591558\n",
      "Accuracy on evaluation data: 8214 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.293782640191\n",
      "Accuracy on evaluation data: 8209 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.278503721923\n",
      "Accuracy on evaluation data: 8187 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.257141029324\n",
      "Accuracy on evaluation data: 8234 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.220404750683\n",
      "Accuracy on evaluation data: 8213 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.205179567215\n",
      "Accuracy on evaluation data: 8250 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.186764312418\n",
      "Accuracy on evaluation data: 8280 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.181524948751\n",
      "Accuracy on evaluation data: 8261 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.164229882414\n",
      "Accuracy on evaluation data: 8266 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.151461116791\n",
      "Accuracy on evaluation data: 8269 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.141019587807\n",
      "Accuracy on evaluation data: 8271 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.136027429028\n",
      "Accuracy on evaluation data: 8269 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.125821208241\n",
      "Accuracy on evaluation data: 8285 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.118998143792\n",
      "Accuracy on evaluation data: 8293 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.113170951957\n",
      "Accuracy on evaluation data: 8285 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.108104444096\n",
      "Accuracy on evaluation data: 8297 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.102029914828\n",
      "Accuracy on evaluation data: 8301 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.0975037464352\n",
      "Accuracy on evaluation data: 8301 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.0930380968347\n",
      "Accuracy on evaluation data: 8307 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.0893421936343\n",
      "Accuracy on evaluation data: 8310 / 10000\n",
      "\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 0.0853760782132\n",
      "Accuracy on evaluation data: 8309 / 10000\n",
      "\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 0.0818258501661\n",
      "Accuracy on evaluation data: 8321 / 10000\n",
      "\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 0.0788323814418\n",
      "Accuracy on evaluation data: 8324 / 10000\n",
      "\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 0.075507007673\n",
      "Accuracy on evaluation data: 8317 / 10000\n",
      "\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 0.0729992282801\n",
      "Accuracy on evaluation data: 8322 / 10000\n",
      "\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 0.0706727575021\n",
      "Accuracy on evaluation data: 8322 / 10000\n",
      "\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 0.0685119448975\n",
      "Accuracy on evaluation data: 8327 / 10000\n",
      "\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 0.0656271106843\n",
      "Accuracy on evaluation data: 8326 / 10000\n",
      "\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 0.063416482929\n",
      "Accuracy on evaluation data: 8340 / 10000\n",
      "\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 0.0613421718952\n",
      "Accuracy on evaluation data: 8343 / 10000\n",
      "\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 0.0594496778016\n",
      "Accuracy on evaluation data: 8341 / 10000\n",
      "\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 0.0577602684321\n",
      "Accuracy on evaluation data: 8339 / 10000\n",
      "\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 0.0560429082426\n",
      "Accuracy on evaluation data: 8348 / 10000\n",
      "\n",
      "Epoch 43 training complete\n",
      "Cost on training data: 0.0550117991732\n",
      "Accuracy on evaluation data: 8343 / 10000\n",
      "\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 0.0535663433921\n",
      "Accuracy on evaluation data: 8356 / 10000\n",
      "\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 0.0511764793077\n",
      "Accuracy on evaluation data: 8355 / 10000\n",
      "\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 0.0496556371023\n",
      "Accuracy on evaluation data: 8354 / 10000\n",
      "\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 0.0482929105141\n",
      "Accuracy on evaluation data: 8369 / 10000\n",
      "\n",
      "Epoch 48 training complete\n",
      "Cost on training data: 0.0467369714042\n",
      "Accuracy on evaluation data: 8367 / 10000\n",
      "\n",
      "Epoch 49 training complete\n",
      "Cost on training data: 0.045379659319\n",
      "Accuracy on evaluation data: 8365 / 10000\n",
      "\n",
      "Epoch 50 training complete\n",
      "Cost on training data: 0.0442700802392\n",
      "Accuracy on evaluation data: 8367 / 10000\n",
      "\n",
      "Epoch 51 training complete\n",
      "Cost on training data: 0.0429613604657\n",
      "Accuracy on evaluation data: 8380 / 10000\n",
      "\n",
      "Epoch 52 training complete\n",
      "Cost on training data: 0.0417331339673\n",
      "Accuracy on evaluation data: 8372 / 10000\n",
      "\n",
      "Epoch 53 training complete\n",
      "Cost on training data: 0.0406300702435\n",
      "Accuracy on evaluation data: 8368 / 10000\n",
      "\n",
      "Epoch 54 training complete\n",
      "Cost on training data: 0.0396982369781\n",
      "Accuracy on evaluation data: 8367 / 10000\n",
      "\n",
      "Epoch 55 training complete\n",
      "Cost on training data: 0.0386313985254\n",
      "Accuracy on evaluation data: 8377 / 10000\n",
      "\n",
      "Epoch 56 training complete\n",
      "Cost on training data: 0.0375131812719\n",
      "Accuracy on evaluation data: 8375 / 10000\n",
      "\n",
      "Epoch 57 training complete\n",
      "Cost on training data: 0.0366970218016\n",
      "Accuracy on evaluation data: 8374 / 10000\n",
      "\n",
      "Epoch 58 training complete\n",
      "Cost on training data: 0.0357568795542\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 59 training complete\n",
      "Cost on training data: 0.0349898191274\n",
      "Accuracy on evaluation data: 8379 / 10000\n",
      "\n",
      "Epoch 60 training complete\n",
      "Cost on training data: 0.034174798677\n",
      "Accuracy on evaluation data: 8377 / 10000\n",
      "\n",
      "Epoch 61 training complete\n",
      "Cost on training data: 0.0333497498132\n",
      "Accuracy on evaluation data: 8382 / 10000\n",
      "\n",
      "Epoch 62 training complete\n",
      "Cost on training data: 0.032586510073\n",
      "Accuracy on evaluation data: 8379 / 10000\n",
      "\n",
      "Epoch 63 training complete\n",
      "Cost on training data: 0.0319598670633\n",
      "Accuracy on evaluation data: 8392 / 10000\n",
      "\n",
      "Epoch 64 training complete\n",
      "Cost on training data: 0.0312627414955\n",
      "Accuracy on evaluation data: 8382 / 10000\n",
      "\n",
      "Epoch 65 training complete\n",
      "Cost on training data: 0.0306482916975\n",
      "Accuracy on evaluation data: 8376 / 10000\n",
      "\n",
      "Epoch 66 training complete\n",
      "Cost on training data: 0.0299378609552\n",
      "Accuracy on evaluation data: 8383 / 10000\n",
      "\n",
      "Epoch 67 training complete\n",
      "Cost on training data: 0.0294867372569\n",
      "Accuracy on evaluation data: 8382 / 10000\n",
      "\n",
      "Epoch 68 training complete\n",
      "Cost on training data: 0.0287658388323\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 69 training complete\n",
      "Cost on training data: 0.0282363949849\n",
      "Accuracy on evaluation data: 8382 / 10000\n",
      "\n",
      "Epoch 70 training complete\n",
      "Cost on training data: 0.0277045900785\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "\n",
      "Epoch 71 training complete\n",
      "Cost on training data: 0.0271450342905\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 72 training complete\n",
      "Cost on training data: 0.0266710709287\n",
      "Accuracy on evaluation data: 8392 / 10000\n",
      "\n",
      "Epoch 73 training complete\n",
      "Cost on training data: 0.0261977606282\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 74 training complete\n",
      "Cost on training data: 0.0257326416428\n",
      "Accuracy on evaluation data: 8387 / 10000\n",
      "\n",
      "Epoch 75 training complete\n",
      "Cost on training data: 0.0252852199508\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 76 training complete\n",
      "Cost on training data: 0.0248516193993\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 77 training complete\n",
      "Cost on training data: 0.0244572519469\n",
      "Accuracy on evaluation data: 8389 / 10000\n",
      "\n",
      "Epoch 78 training complete\n",
      "Cost on training data: 0.0240272716397\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 79 training complete\n",
      "Cost on training data: 0.0236145672557\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 80 training complete\n",
      "Cost on training data: 0.0233298181676\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 81 training complete\n",
      "Cost on training data: 0.0228774285719\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 82 training complete\n",
      "Cost on training data: 0.0225323750228\n",
      "Accuracy on evaluation data: 8400 / 10000\n",
      "\n",
      "Epoch 83 training complete\n",
      "Cost on training data: 0.022176037284\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 84 training complete\n",
      "Cost on training data: 0.0218280571753\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 85 training complete\n",
      "Cost on training data: 0.0215420604335\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 86 training complete\n",
      "Cost on training data: 0.021200453459\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 87 training complete\n",
      "Cost on training data: 0.0208693786851\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 88 training complete\n",
      "Cost on training data: 0.0205935792782\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 89 training complete\n",
      "Cost on training data: 0.0203041017779\n",
      "Accuracy on evaluation data: 8387 / 10000\n",
      "\n",
      "Epoch 90 training complete\n",
      "Cost on training data: 0.0199914215134\n",
      "Accuracy on evaluation data: 8387 / 10000\n",
      "\n",
      "Epoch 91 training complete\n",
      "Cost on training data: 0.0197069804507\n",
      "Accuracy on evaluation data: 8389 / 10000\n",
      "\n",
      "Epoch 92 training complete\n",
      "Cost on training data: 0.0194416894777\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 93 training complete\n",
      "Cost on training data: 0.0191750512757\n",
      "Accuracy on evaluation data: 8396 / 10000\n",
      "\n",
      "Epoch 94 training complete\n",
      "Cost on training data: 0.018918627591\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 95 training complete\n",
      "Cost on training data: 0.018647702402\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 96 training complete\n",
      "Cost on training data: 0.0184565066736\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 97 training complete\n",
      "Cost on training data: 0.0181839559708\n",
      "Accuracy on evaluation data: 8391 / 10000\n",
      "\n",
      "Epoch 98 training complete\n",
      "Cost on training data: 0.0179312897839\n",
      "Accuracy on evaluation data: 8391 / 10000\n",
      "\n",
      "Epoch 99 training complete\n",
      "Cost on training data: 0.0177149368696\n",
      "Accuracy on evaluation data: 8396 / 10000\n",
      "\n",
      "Epoch 100 training complete\n",
      "Cost on training data: 0.017493667192\n",
      "Accuracy on evaluation data: 8387 / 10000\n",
      "\n",
      "Epoch 101 training complete\n",
      "Cost on training data: 0.0172562709348\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 102 training complete\n",
      "Cost on training data: 0.0170440716409\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 103 training complete\n",
      "Cost on training data: 0.01684531843\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 104 training complete\n",
      "Cost on training data: 0.0166393250685\n",
      "Accuracy on evaluation data: 8386 / 10000\n",
      "\n",
      "Epoch 105 training complete\n",
      "Cost on training data: 0.0164378212227\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 106 training complete\n",
      "Cost on training data: 0.016253275472\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 107 training complete\n",
      "Cost on training data: 0.0160591772275\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 108 training complete\n",
      "Cost on training data: 0.015871947379\n",
      "Accuracy on evaluation data: 8389 / 10000\n",
      "\n",
      "Epoch 109 training complete\n",
      "Cost on training data: 0.0156926834642\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 110 training complete\n",
      "Cost on training data: 0.015521227673\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 111 training complete\n",
      "Cost on training data: 0.0153394490162\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 112 training complete\n",
      "Cost on training data: 0.0151741658912\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 113 training complete\n",
      "Cost on training data: 0.0150272810164\n",
      "Accuracy on evaluation data: 8383 / 10000\n",
      "\n",
      "Epoch 114 training complete\n",
      "Cost on training data: 0.0148561721291\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 115 training complete\n",
      "Cost on training data: 0.0146946599403\n",
      "Accuracy on evaluation data: 8389 / 10000\n",
      "\n",
      "Epoch 116 training complete\n",
      "Cost on training data: 0.014532804829\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 117 training complete\n",
      "Cost on training data: 0.0143900883379\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 118 training complete\n",
      "Cost on training data: 0.0142285086223\n",
      "Accuracy on evaluation data: 8386 / 10000\n",
      "\n",
      "Epoch 119 training complete\n",
      "Cost on training data: 0.014090525052\n",
      "Accuracy on evaluation data: 8389 / 10000\n",
      "\n",
      "Epoch 120 training complete\n",
      "Cost on training data: 0.0139437457939\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 121 training complete\n",
      "Cost on training data: 0.0138128900462\n",
      "Accuracy on evaluation data: 8392 / 10000\n",
      "\n",
      "Epoch 122 training complete\n",
      "Cost on training data: 0.0136639940761\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 123 training complete\n",
      "Cost on training data: 0.0135332432737\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "\n",
      "Epoch 124 training complete\n",
      "Cost on training data: 0.0133967856293\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 125 training complete\n",
      "Cost on training data: 0.0132764536582\n",
      "Accuracy on evaluation data: 8391 / 10000\n",
      "\n",
      "Epoch 126 training complete\n",
      "Cost on training data: 0.0131347734122\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 127 training complete\n",
      "Cost on training data: 0.0130121746932\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 128 training complete\n",
      "Cost on training data: 0.012888989296\n",
      "Accuracy on evaluation data: 8390 / 10000\n",
      "\n",
      "Epoch 129 training complete\n",
      "Cost on training data: 0.012769738799\n",
      "Accuracy on evaluation data: 8399 / 10000\n",
      "\n",
      "Epoch 130 training complete\n",
      "Cost on training data: 0.012645656986\n",
      "Accuracy on evaluation data: 8396 / 10000\n",
      "\n",
      "Epoch 131 training complete\n",
      "Cost on training data: 0.0125247029666\n",
      "Accuracy on evaluation data: 8396 / 10000\n",
      "\n",
      "Epoch 132 training complete\n",
      "Cost on training data: 0.0124129226842\n",
      "Accuracy on evaluation data: 8400 / 10000\n",
      "\n",
      "Epoch 133 training complete\n",
      "Cost on training data: 0.0123007073713\n",
      "Accuracy on evaluation data: 8387 / 10000\n",
      "\n",
      "Epoch 134 training complete\n",
      "Cost on training data: 0.0121844893057\n",
      "Accuracy on evaluation data: 8394 / 10000\n",
      "\n",
      "Epoch 135 training complete\n",
      "Cost on training data: 0.012075179773\n",
      "Accuracy on evaluation data: 8393 / 10000\n",
      "\n",
      "Epoch 136 training complete\n",
      "Cost on training data: 0.0119690734455\n",
      "Accuracy on evaluation data: 8396 / 10000\n",
      "\n",
      "Epoch 137 training complete\n",
      "Cost on training data: 0.0118719058452\n",
      "Accuracy on evaluation data: 8399 / 10000\n",
      "\n",
      "Epoch 138 training complete\n",
      "Cost on training data: 0.0117565048852\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 139 training complete\n",
      "Cost on training data: 0.0116522623604\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 140 training complete\n",
      "Cost on training data: 0.0115496549402\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 141 training complete\n",
      "Cost on training data: 0.0114519513262\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 142 training complete\n",
      "Cost on training data: 0.0113583452409\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "\n",
      "Epoch 143 training complete\n",
      "Cost on training data: 0.0112628146888\n",
      "Accuracy on evaluation data: 8399 / 10000\n",
      "\n",
      "Epoch 144 training complete\n",
      "Cost on training data: 0.0111646535008\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "\n",
      "Epoch 145 training complete\n",
      "Cost on training data: 0.0110691200613\n",
      "Accuracy on evaluation data: 8402 / 10000\n",
      "\n",
      "Epoch 146 training complete\n",
      "Cost on training data: 0.0109729443071\n",
      "Accuracy on evaluation data: 8400 / 10000\n",
      "\n",
      "Epoch 147 training complete\n",
      "Cost on training data: 0.0108794481279\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 148 training complete\n",
      "Cost on training data: 0.0107891179756\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "\n",
      "Epoch 149 training complete\n",
      "Cost on training data: 0.0106997383682\n",
      "Accuracy on evaluation data: 8405 / 10000\n",
      "\n",
      "Epoch 150 training complete\n",
      "Cost on training data: 0.0106108275535\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 151 training complete\n",
      "Cost on training data: 0.0105248071861\n",
      "Accuracy on evaluation data: 8403 / 10000\n",
      "\n",
      "Epoch 152 training complete\n",
      "Cost on training data: 0.0104427062776\n",
      "Accuracy on evaluation data: 8406 / 10000\n",
      "\n",
      "Epoch 153 training complete\n",
      "Cost on training data: 0.0103576748103\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 154 training complete\n",
      "Cost on training data: 0.0102717607083\n",
      "Accuracy on evaluation data: 8401 / 10000\n",
      "\n",
      "Epoch 155 training complete\n",
      "Cost on training data: 0.0101896908477\n",
      "Accuracy on evaluation data: 8399 / 10000\n",
      "\n",
      "Epoch 156 training complete\n",
      "Cost on training data: 0.0101094162909\n",
      "Accuracy on evaluation data: 8402 / 10000\n",
      "\n",
      "Epoch 157 training complete\n",
      "Cost on training data: 0.0100295737472\n",
      "Accuracy on evaluation data: 8410 / 10000\n",
      "\n",
      "Epoch 158 training complete\n",
      "Cost on training data: 0.00994870760442\n",
      "Accuracy on evaluation data: 8411 / 10000\n",
      "\n",
      "Epoch 159 training complete\n",
      "Cost on training data: 0.00987142193982\n",
      "Accuracy on evaluation data: 8413 / 10000\n",
      "\n",
      "Epoch 160 training complete\n",
      "Cost on training data: 0.00979350401286\n",
      "Accuracy on evaluation data: 8408 / 10000\n",
      "\n",
      "Epoch 161 training complete\n",
      "Cost on training data: 0.00971809103429\n",
      "Accuracy on evaluation data: 8408 / 10000\n",
      "\n",
      "Epoch 162 training complete\n",
      "Cost on training data: 0.00964366290964\n",
      "Accuracy on evaluation data: 8410 / 10000\n",
      "\n",
      "Epoch 163 training complete\n",
      "Cost on training data: 0.00956785861964\n",
      "Accuracy on evaluation data: 8411 / 10000\n",
      "\n",
      "Epoch 164 training complete\n",
      "Cost on training data: 0.00949868856336\n",
      "Accuracy on evaluation data: 8411 / 10000\n",
      "\n",
      "Epoch 165 training complete\n",
      "Cost on training data: 0.00942466116805\n",
      "Accuracy on evaluation data: 8412 / 10000\n",
      "\n",
      "Epoch 166 training complete\n",
      "Cost on training data: 0.00935356027939\n",
      "Accuracy on evaluation data: 8412 / 10000\n",
      "\n",
      "Epoch 167 training complete\n",
      "Cost on training data: 0.00928234535522\n",
      "Accuracy on evaluation data: 8409 / 10000\n",
      "\n",
      "Epoch 168 training complete\n",
      "Cost on training data: 0.0092105637502\n",
      "Accuracy on evaluation data: 8408 / 10000\n",
      "\n",
      "Epoch 169 training complete\n",
      "Cost on training data: 0.00913982688496\n",
      "Accuracy on evaluation data: 8408 / 10000\n",
      "\n",
      "Epoch 170 training complete\n",
      "Cost on training data: 0.00907693973043\n",
      "Accuracy on evaluation data: 8409 / 10000\n",
      "\n",
      "Epoch 171 training complete\n",
      "Cost on training data: 0.00900389264912\n",
      "Accuracy on evaluation data: 8404 / 10000\n",
      "\n",
      "Epoch 172 training complete\n",
      "Cost on training data: 0.00893427189663\n",
      "Accuracy on evaluation data: 8413 / 10000\n",
      "\n",
      "Epoch 173 training complete\n",
      "Cost on training data: 0.00886716037162\n",
      "Accuracy on evaluation data: 8410 / 10000\n",
      "\n",
      "Epoch 174 training complete\n",
      "Cost on training data: 0.00879975292294\n",
      "Accuracy on evaluation data: 8412 / 10000\n",
      "\n",
      "Epoch 175 training complete\n",
      "Cost on training data: 0.00873436628212\n",
      "Accuracy on evaluation data: 8416 / 10000\n",
      "\n",
      "Epoch 176 training complete\n",
      "Cost on training data: 0.00866840200254\n",
      "Accuracy on evaluation data: 8417 / 10000\n",
      "\n",
      "Epoch 177 training complete\n",
      "Cost on training data: 0.00860359565637\n",
      "Accuracy on evaluation data: 8414 / 10000\n",
      "\n",
      "Epoch 178 training complete\n",
      "Cost on training data: 0.00854105592139\n",
      "Accuracy on evaluation data: 8414 / 10000\n",
      "\n",
      "Epoch 179 training complete\n",
      "Cost on training data: 0.00847525108619\n",
      "Accuracy on evaluation data: 8415 / 10000\n",
      "\n",
      "Epoch 180 training complete\n",
      "Cost on training data: 0.00841473811317\n",
      "Accuracy on evaluation data: 8417 / 10000\n",
      "\n",
      "Epoch 181 training complete\n",
      "Cost on training data: 0.00834763953004\n",
      "Accuracy on evaluation data: 8417 / 10000\n",
      "\n",
      "Epoch 182 training complete\n",
      "Cost on training data: 0.00828546216169\n",
      "Accuracy on evaluation data: 8414 / 10000\n",
      "\n",
      "Epoch 183 training complete\n",
      "Cost on training data: 0.00822463834744\n",
      "Accuracy on evaluation data: 8418 / 10000\n",
      "\n",
      "Epoch 184 training complete\n",
      "Cost on training data: 0.00816131625144\n",
      "Accuracy on evaluation data: 8418 / 10000\n",
      "\n",
      "Epoch 185 training complete\n",
      "Cost on training data: 0.00810185208494\n",
      "Accuracy on evaluation data: 8419 / 10000\n",
      "\n",
      "Epoch 186 training complete\n",
      "Cost on training data: 0.00803864214681\n",
      "Accuracy on evaluation data: 8420 / 10000\n",
      "\n",
      "Epoch 187 training complete\n",
      "Cost on training data: 0.00798047769702\n",
      "Accuracy on evaluation data: 8419 / 10000\n",
      "\n",
      "Epoch 188 training complete\n",
      "Cost on training data: 0.0079203465246\n",
      "Accuracy on evaluation data: 8418 / 10000\n",
      "\n",
      "Epoch 189 training complete\n",
      "Cost on training data: 0.00786345969248\n",
      "Accuracy on evaluation data: 8419 / 10000\n",
      "\n",
      "Epoch 190 training complete\n",
      "Cost on training data: 0.00780550411605\n",
      "Accuracy on evaluation data: 8422 / 10000\n",
      "\n",
      "Epoch 191 training complete\n",
      "Cost on training data: 0.00775069283669\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 192 training complete\n",
      "Cost on training data: 0.00769486816385\n",
      "Accuracy on evaluation data: 8422 / 10000\n",
      "\n",
      "Epoch 193 training complete\n",
      "Cost on training data: 0.00764177456105\n",
      "Accuracy on evaluation data: 8421 / 10000\n",
      "\n",
      "Epoch 194 training complete\n",
      "Cost on training data: 0.00758892209299\n",
      "Accuracy on evaluation data: 8423 / 10000\n",
      "\n",
      "Epoch 195 training complete\n",
      "Cost on training data: 0.00753671409407\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 196 training complete\n",
      "Cost on training data: 0.00748635153104\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 197 training complete\n",
      "Cost on training data: 0.0074365389745\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 198 training complete\n",
      "Cost on training data: 0.00738774921542\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 199 training complete\n",
      "Cost on training data: 0.00734037283542\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 200 training complete\n",
      "Cost on training data: 0.00729288898571\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 201 training complete\n",
      "Cost on training data: 0.00724578177025\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 202 training complete\n",
      "Cost on training data: 0.00720043180544\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 203 training complete\n",
      "Cost on training data: 0.00715630601781\n",
      "Accuracy on evaluation data: 8422 / 10000\n",
      "\n",
      "Epoch 204 training complete\n",
      "Cost on training data: 0.00711063033003\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 205 training complete\n",
      "Cost on training data: 0.00706770835081\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 206 training complete\n",
      "Cost on training data: 0.00702337377421\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 207 training complete\n",
      "Cost on training data: 0.00698153812487\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 208 training complete\n",
      "Cost on training data: 0.00693847046274\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 209 training complete\n",
      "Cost on training data: 0.00689652615387\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 210 training complete\n",
      "Cost on training data: 0.00685583785261\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 211 training complete\n",
      "Cost on training data: 0.0068159285328\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 212 training complete\n",
      "Cost on training data: 0.0067753168725\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 213 training complete\n",
      "Cost on training data: 0.00673525150426\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 214 training complete\n",
      "Cost on training data: 0.00669683352069\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 215 training complete\n",
      "Cost on training data: 0.00665782014529\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 216 training complete\n",
      "Cost on training data: 0.00662002344474\n",
      "Accuracy on evaluation data: 8425 / 10000\n",
      "\n",
      "Epoch 217 training complete\n",
      "Cost on training data: 0.006581892852\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 218 training complete\n",
      "Cost on training data: 0.00654451105366\n",
      "Accuracy on evaluation data: 8429 / 10000\n",
      "\n",
      "Epoch 219 training complete\n",
      "Cost on training data: 0.00650763612533\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 220 training complete\n",
      "Cost on training data: 0.00647177180023\n",
      "Accuracy on evaluation data: 8424 / 10000\n",
      "\n",
      "Epoch 221 training complete\n",
      "Cost on training data: 0.0064359811839\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 222 training complete\n",
      "Cost on training data: 0.00640068288267\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 223 training complete\n",
      "Cost on training data: 0.00636459569702\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 224 training complete\n",
      "Cost on training data: 0.00633002311624\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 225 training complete\n",
      "Cost on training data: 0.00629533341931\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 226 training complete\n",
      "Cost on training data: 0.00626154243322\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 227 training complete\n",
      "Cost on training data: 0.00622745944808\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 228 training complete\n",
      "Cost on training data: 0.00619449473611\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 229 training complete\n",
      "Cost on training data: 0.00616130336971\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 230 training complete\n",
      "Cost on training data: 0.00612923975813\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 231 training complete\n",
      "Cost on training data: 0.00609637501019\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 232 training complete\n",
      "Cost on training data: 0.00606445328338\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 233 training complete\n",
      "Cost on training data: 0.00603317465293\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 234 training complete\n",
      "Cost on training data: 0.00600158707296\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 235 training complete\n",
      "Cost on training data: 0.00597081708202\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 236 training complete\n",
      "Cost on training data: 0.00594028894313\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 237 training complete\n",
      "Cost on training data: 0.00590972456772\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "\n",
      "Epoch 238 training complete\n",
      "Cost on training data: 0.00588033597977\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 239 training complete\n",
      "Cost on training data: 0.00584961051019\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 240 training complete\n",
      "Cost on training data: 0.00582022364019\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 241 training complete\n",
      "Cost on training data: 0.00579155066754\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 242 training complete\n",
      "Cost on training data: 0.00576279823285\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 243 training complete\n",
      "Cost on training data: 0.0057337161379\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 244 training complete\n",
      "Cost on training data: 0.00570524738941\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 245 training complete\n",
      "Cost on training data: 0.00567712547274\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 246 training complete\n",
      "Cost on training data: 0.0056494815301\n",
      "Accuracy on evaluation data: 8436 / 10000\n",
      "\n",
      "Epoch 247 training complete\n",
      "Cost on training data: 0.00562167007712\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 248 training complete\n",
      "Cost on training data: 0.00559435640898\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "\n",
      "Epoch 249 training complete\n",
      "Cost on training data: 0.0055672235031\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 250 training complete\n",
      "Cost on training data: 0.00554070460911\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 251 training complete\n",
      "Cost on training data: 0.00551402168027\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 252 training complete\n",
      "Cost on training data: 0.00548763875911\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "\n",
      "Epoch 253 training complete\n",
      "Cost on training data: 0.00546208199011\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "\n",
      "Epoch 254 training complete\n",
      "Cost on training data: 0.00543590375518\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 255 training complete\n",
      "Cost on training data: 0.00540999506717\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 256 training complete\n",
      "Cost on training data: 0.00538421951008\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 257 training complete\n",
      "Cost on training data: 0.00535903298918\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 258 training complete\n",
      "Cost on training data: 0.00533422789667\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 259 training complete\n",
      "Cost on training data: 0.00530935673067\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 260 training complete\n",
      "Cost on training data: 0.00528454114184\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 261 training complete\n",
      "Cost on training data: 0.00526014979577\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 262 training complete\n",
      "Cost on training data: 0.00523593634621\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 263 training complete\n",
      "Cost on training data: 0.00521159607782\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 264 training complete\n",
      "Cost on training data: 0.00518794362075\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 265 training complete\n",
      "Cost on training data: 0.00516442528677\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 266 training complete\n",
      "Cost on training data: 0.00514095860676\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 267 training complete\n",
      "Cost on training data: 0.0051177840021\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 268 training complete\n",
      "Cost on training data: 0.005094763727\n",
      "Accuracy on evaluation data: 8434 / 10000\n",
      "\n",
      "Epoch 269 training complete\n",
      "Cost on training data: 0.00507155426322\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 270 training complete\n",
      "Cost on training data: 0.00504922588987\n",
      "Accuracy on evaluation data: 8433 / 10000\n",
      "\n",
      "Epoch 271 training complete\n",
      "Cost on training data: 0.00502634693762\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 272 training complete\n",
      "Cost on training data: 0.00500407705601\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 273 training complete\n",
      "Cost on training data: 0.00498176150274\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 274 training complete\n",
      "Cost on training data: 0.00495998124078\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 275 training complete\n",
      "Cost on training data: 0.00493804493188\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 276 training complete\n",
      "Cost on training data: 0.0049162865822\n",
      "Accuracy on evaluation data: 8429 / 10000\n",
      "\n",
      "Epoch 277 training complete\n",
      "Cost on training data: 0.00489492612357\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 278 training complete\n",
      "Cost on training data: 0.00487339522475\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 279 training complete\n",
      "Cost on training data: 0.00485238418511\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 280 training complete\n",
      "Cost on training data: 0.00483135547669\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 281 training complete\n",
      "Cost on training data: 0.00481028493002\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 282 training complete\n",
      "Cost on training data: 0.00478941945839\n",
      "Accuracy on evaluation data: 8429 / 10000\n",
      "\n",
      "Epoch 283 training complete\n",
      "Cost on training data: 0.00476906085247\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 284 training complete\n",
      "Cost on training data: 0.00474860098182\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 285 training complete\n",
      "Cost on training data: 0.0047282394904\n",
      "Accuracy on evaluation data: 8429 / 10000\n",
      "\n",
      "Epoch 286 training complete\n",
      "Cost on training data: 0.00470816688476\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 287 training complete\n",
      "Cost on training data: 0.00468830629137\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 288 training complete\n",
      "Cost on training data: 0.00466865707647\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 289 training complete\n",
      "Cost on training data: 0.00464898271719\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 290 training complete\n",
      "Cost on training data: 0.00462931713006\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 291 training complete\n",
      "Cost on training data: 0.00461012542328\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 292 training complete\n",
      "Cost on training data: 0.0045907944442\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 293 training complete\n",
      "Cost on training data: 0.00457168474703\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 294 training complete\n",
      "Cost on training data: 0.0045527124492\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 295 training complete\n",
      "Cost on training data: 0.00453408746537\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 296 training complete\n",
      "Cost on training data: 0.00451576683813\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 297 training complete\n",
      "Cost on training data: 0.00449702237829\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 298 training complete\n",
      "Cost on training data: 0.00447885746763\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 299 training complete\n",
      "Cost on training data: 0.0044604741794\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 300 training complete\n",
      "Cost on training data: 0.00444241405135\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 301 training complete\n",
      "Cost on training data: 0.00442444546669\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 302 training complete\n",
      "Cost on training data: 0.00440668989068\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 303 training complete\n",
      "Cost on training data: 0.00438920131514\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 304 training complete\n",
      "Cost on training data: 0.00437142824298\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 305 training complete\n",
      "Cost on training data: 0.00435394247867\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 306 training complete\n",
      "Cost on training data: 0.00433677657542\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 307 training complete\n",
      "Cost on training data: 0.00431953235536\n",
      "Accuracy on evaluation data: 8429 / 10000\n",
      "\n",
      "Epoch 308 training complete\n",
      "Cost on training data: 0.00430270478693\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 309 training complete\n",
      "Cost on training data: 0.0042855454597\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 310 training complete\n",
      "Cost on training data: 0.00426877910942\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 311 training complete\n",
      "Cost on training data: 0.00425206975281\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "\n",
      "Epoch 312 training complete\n",
      "Cost on training data: 0.00423543533792\n",
      "Accuracy on evaluation data: 8430 / 10000\n",
      "\n",
      "Epoch 313 training complete\n",
      "Cost on training data: 0.00421925361753\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-45ba5d965645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyCost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlarge_weight_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor_evaluation_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor_training_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, lmbda, evaluation_data, monitor_evaluation_cost, monitor_evaluation_accuracy, monitor_training_cost, monitor_training_accuracy)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mevaluation_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 print \"Accuracy on evaluation data: {} / {}\".format(\n\u001b[1;32m--> 185\u001b[1;33m                     self.accuracy(evaluation_data), n_data)\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mevaluation_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, data, convert)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             results = [(np.argmax(self.feedforward(x)), y)\n\u001b[1;32m--> 271\u001b[1;33m                         for (x, y) in data]\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36mfeedforward\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;34m\"\"\"Return the output of the network if ``a`` is input.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost) \n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True, monitor_training_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 3.01171313621\n",
      "Accuracy on training data: 669 / 1000\n",
      "Cost on evaluation data: 2.24653679603\n",
      "Accuracy on evaluation data: 5678 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 2.60169647596\n",
      "Accuracy on training data: 762 / 1000\n",
      "Cost on evaluation data: 1.96560088611\n",
      "Accuracy on evaluation data: 6439 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 2.30962048631\n",
      "Accuracy on training data: 825 / 1000\n",
      "Cost on evaluation data: 1.72977951993\n",
      "Accuracy on evaluation data: 6994 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 2.11462714929\n",
      "Accuracy on training data: 851 / 1000\n",
      "Cost on evaluation data: 1.5841266445\n",
      "Accuracy on evaluation data: 7276 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 1.94563361911\n",
      "Accuracy on training data: 894 / 1000\n",
      "Cost on evaluation data: 1.5111658934\n",
      "Accuracy on evaluation data: 7391 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 1.82147250306\n",
      "Accuracy on training data: 910 / 1000\n",
      "Cost on evaluation data: 1.44432406444\n",
      "Accuracy on evaluation data: 7598 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 1.76674180917\n",
      "Accuracy on training data: 920 / 1000\n",
      "Cost on evaluation data: 1.45687211917\n",
      "Accuracy on evaluation data: 7643 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 1.6731322534\n",
      "Accuracy on training data: 933 / 1000\n",
      "Cost on evaluation data: 1.39396280276\n",
      "Accuracy on evaluation data: 7773 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 1.60319353257\n",
      "Accuracy on training data: 940 / 1000\n",
      "Cost on evaluation data: 1.3727119941\n",
      "Accuracy on evaluation data: 7820 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 1.55093053932\n",
      "Accuracy on training data: 946 / 1000\n",
      "Cost on evaluation data: 1.36084899164\n",
      "Accuracy on evaluation data: 7871 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 1.50957996714\n",
      "Accuracy on training data: 954 / 1000\n",
      "Cost on evaluation data: 1.34837560318\n",
      "Accuracy on evaluation data: 7873 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 1.47634496882\n",
      "Accuracy on training data: 955 / 1000\n",
      "Cost on evaluation data: 1.35170039997\n",
      "Accuracy on evaluation data: 7911 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 1.44111057039\n",
      "Accuracy on training data: 955 / 1000\n",
      "Cost on evaluation data: 1.3551336022\n",
      "Accuracy on evaluation data: 7889 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 1.39873036054\n",
      "Accuracy on training data: 967 / 1000\n",
      "Cost on evaluation data: 1.33253835972\n",
      "Accuracy on evaluation data: 7987 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 1.36090591581\n",
      "Accuracy on training data: 970 / 1000\n",
      "Cost on evaluation data: 1.32944009678\n",
      "Accuracy on evaluation data: 7967 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 1.31966613769\n",
      "Accuracy on training data: 976 / 1000\n",
      "Cost on evaluation data: 1.31139983901\n",
      "Accuracy on evaluation data: 8023 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 1.30012362832\n",
      "Accuracy on training data: 978 / 1000\n",
      "Cost on evaluation data: 1.33307143399\n",
      "Accuracy on evaluation data: 7968 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 1.26492652073\n",
      "Accuracy on training data: 983 / 1000\n",
      "Cost on evaluation data: 1.30683815106\n",
      "Accuracy on evaluation data: 8037 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 1.24784354232\n",
      "Accuracy on training data: 986 / 1000\n",
      "Cost on evaluation data: 1.30864978764\n",
      "Accuracy on evaluation data: 8008 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 1.23273211018\n",
      "Accuracy on training data: 984 / 1000\n",
      "Cost on evaluation data: 1.34388281395\n",
      "Accuracy on evaluation data: 8013 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 1.19588782625\n",
      "Accuracy on training data: 987 / 1000\n",
      "Cost on evaluation data: 1.29954502458\n",
      "Accuracy on evaluation data: 8084 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 1.18369708682\n",
      "Accuracy on training data: 988 / 1000\n",
      "Cost on evaluation data: 1.29635338424\n",
      "Accuracy on evaluation data: 8073 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 1.16569169261\n",
      "Accuracy on training data: 989 / 1000\n",
      "Cost on evaluation data: 1.30131718863\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 1.1485267303\n",
      "Accuracy on training data: 989 / 1000\n",
      "Cost on evaluation data: 1.29868354336\n",
      "Accuracy on evaluation data: 8099 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 1.12723804026\n",
      "Accuracy on training data: 989 / 1000\n",
      "Cost on evaluation data: 1.30594901321\n",
      "Accuracy on evaluation data: 8081 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 1.11282152734\n",
      "Accuracy on training data: 990 / 1000\n",
      "Cost on evaluation data: 1.29541655353\n",
      "Accuracy on evaluation data: 8097 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 1.09494027076\n",
      "Accuracy on training data: 991 / 1000\n",
      "Cost on evaluation data: 1.28174599043\n",
      "Accuracy on evaluation data: 8150 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 1.0818287545\n",
      "Accuracy on training data: 991 / 1000\n",
      "Cost on evaluation data: 1.27381387234\n",
      "Accuracy on evaluation data: 8148 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 1.07254860706\n",
      "Accuracy on training data: 993 / 1000\n",
      "Cost on evaluation data: 1.26754787592\n",
      "Accuracy on evaluation data: 8172 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 1.05380089393\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.27742491875\n",
      "Accuracy on evaluation data: 8156 / 10000\n",
      "\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 1.04283431109\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 1.29026813934\n",
      "Accuracy on evaluation data: 8149 / 10000\n",
      "\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 1.02860714632\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 1.28027500195\n",
      "Accuracy on evaluation data: 8167 / 10000\n",
      "\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 1.01753748766\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 1.28755282166\n",
      "Accuracy on evaluation data: 8180 / 10000\n",
      "\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 1.00644700518\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.28416360364\n",
      "Accuracy on evaluation data: 8148 / 10000\n",
      "\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 0.995795233476\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 1.28610161185\n",
      "Accuracy on evaluation data: 8160 / 10000\n",
      "\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 0.9820287117\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.26408023103\n",
      "Accuracy on evaluation data: 8192 / 10000\n",
      "\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 0.972032734801\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.26757119497\n",
      "Accuracy on evaluation data: 8206 / 10000\n",
      "\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 0.962570722251\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.26005242092\n",
      "Accuracy on evaluation data: 8217 / 10000\n",
      "\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 0.951631050013\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 1.28051371028\n",
      "Accuracy on evaluation data: 8181 / 10000\n",
      "\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 0.940676333541\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.25884931884\n",
      "Accuracy on evaluation data: 8218 / 10000\n",
      "\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 0.931968050335\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.26442770986\n",
      "Accuracy on evaluation data: 8216 / 10000\n",
      "\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 0.92165116775\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 1.26804858685\n",
      "Accuracy on evaluation data: 8220 / 10000\n",
      "\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 0.912086481394\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.27409475189\n",
      "Accuracy on evaluation data: 8207 / 10000\n",
      "\n",
      "Epoch 43 training complete\n",
      "Cost on training data: 0.90232953025\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.26568562034\n",
      "Accuracy on evaluation data: 8221 / 10000\n",
      "\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 0.892816219936\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.26807094418\n",
      "Accuracy on evaluation data: 8232 / 10000\n",
      "\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 0.884417518283\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.27644670795\n",
      "Accuracy on evaluation data: 8199 / 10000\n",
      "\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 0.874403030346\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.26697872739\n",
      "Accuracy on evaluation data: 8209 / 10000\n",
      "\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 0.866245149692\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.25394001946\n",
      "Accuracy on evaluation data: 8239 / 10000\n",
      "\n",
      "Epoch 48 training complete\n",
      "Cost on training data: 0.857295902808\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.266711543\n",
      "Accuracy on evaluation data: 8217 / 10000\n",
      "\n",
      "Epoch 49 training complete\n",
      "Cost on training data: 0.85140876047\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.27601921391\n",
      "Accuracy on evaluation data: 8191 / 10000\n",
      "\n",
      "Epoch 50 training complete\n",
      "Cost on training data: 0.841584163288\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.26051910033\n",
      "Accuracy on evaluation data: 8239 / 10000\n",
      "\n",
      "Epoch 51 training complete\n",
      "Cost on training data: 0.833928196629\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.26583337624\n",
      "Accuracy on evaluation data: 8234 / 10000\n",
      "\n",
      "Epoch 52 training complete\n",
      "Cost on training data: 0.82470374669\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.24700903767\n",
      "Accuracy on evaluation data: 8257 / 10000\n",
      "\n",
      "Epoch 53 training complete\n",
      "Cost on training data: 0.816609124984\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.25897647451\n",
      "Accuracy on evaluation data: 8233 / 10000\n",
      "\n",
      "Epoch 54 training complete\n",
      "Cost on training data: 0.809568267878\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 1.25212301896\n",
      "Accuracy on evaluation data: 8259 / 10000\n",
      "\n",
      "Epoch 55 training complete\n",
      "Cost on training data: 0.801282500092\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.2466959169\n",
      "Accuracy on evaluation data: 8269 / 10000\n",
      "\n",
      "Epoch 56 training complete\n",
      "Cost on training data: 0.793805986695\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.24894213687\n",
      "Accuracy on evaluation data: 8260 / 10000\n",
      "\n",
      "Epoch 57 training complete\n",
      "Cost on training data: 0.78603497802\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.24339927102\n",
      "Accuracy on evaluation data: 8257 / 10000\n",
      "\n",
      "Epoch 58 training complete\n",
      "Cost on training data: 0.779344053712\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.23892081754\n",
      "Accuracy on evaluation data: 8269 / 10000\n",
      "\n",
      "Epoch 59 training complete\n",
      "Cost on training data: 0.771991834661\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.24773042763\n",
      "Accuracy on evaluation data: 8262 / 10000\n",
      "\n",
      "Epoch 60 training complete\n",
      "Cost on training data: 0.765147249168\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.22424095337\n",
      "Accuracy on evaluation data: 8296 / 10000\n",
      "\n",
      "Epoch 61 training complete\n",
      "Cost on training data: 0.758100989079\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.22430280609\n",
      "Accuracy on evaluation data: 8286 / 10000\n",
      "\n",
      "Epoch 62 training complete\n",
      "Cost on training data: 0.751207918216\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.22824185795\n",
      "Accuracy on evaluation data: 8283 / 10000\n",
      "\n",
      "Epoch 63 training complete\n",
      "Cost on training data: 0.743973626515\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.23176323441\n",
      "Accuracy on evaluation data: 8278 / 10000\n",
      "\n",
      "Epoch 64 training complete\n",
      "Cost on training data: 0.736809957708\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.224219745\n",
      "Accuracy on evaluation data: 8304 / 10000\n",
      "\n",
      "Epoch 65 training complete\n",
      "Cost on training data: 0.730290367085\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.22253052666\n",
      "Accuracy on evaluation data: 8287 / 10000\n",
      "\n",
      "Epoch 66 training complete\n",
      "Cost on training data: 0.723446524831\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.22548284994\n",
      "Accuracy on evaluation data: 8293 / 10000\n",
      "\n",
      "Epoch 67 training complete\n",
      "Cost on training data: 0.717140345032\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.21992696097\n",
      "Accuracy on evaluation data: 8303 / 10000\n",
      "\n",
      "Epoch 68 training complete\n",
      "Cost on training data: 0.710817173976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.22896644601\n",
      "Accuracy on evaluation data: 8293 / 10000\n",
      "\n",
      "Epoch 69 training complete\n",
      "Cost on training data: 0.704014928115\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.22555267407\n",
      "Accuracy on evaluation data: 8302 / 10000\n",
      "\n",
      "Epoch 70 training complete\n",
      "Cost on training data: 0.697713144647\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 1.21783587162\n",
      "Accuracy on evaluation data: 8297 / 10000\n",
      "\n",
      "Epoch 71 training complete\n",
      "Cost on training data: 0.691265665433\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.21681179217\n",
      "Accuracy on evaluation data: 8305 / 10000\n",
      "\n",
      "Epoch 72 training complete\n",
      "Cost on training data: 0.685817181027\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.21453477188\n",
      "Accuracy on evaluation data: 8297 / 10000\n",
      "\n",
      "Epoch 73 training complete\n",
      "Cost on training data: 0.678865205203\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.2056555486\n",
      "Accuracy on evaluation data: 8321 / 10000\n",
      "\n",
      "Epoch 74 training complete\n",
      "Cost on training data: 0.672875198368\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.21077187846\n",
      "Accuracy on evaluation data: 8310 / 10000\n",
      "\n",
      "Epoch 75 training complete\n",
      "Cost on training data: 0.667055405068\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.20851169522\n",
      "Accuracy on evaluation data: 8318 / 10000\n",
      "\n",
      "Epoch 76 training complete\n",
      "Cost on training data: 0.661548125777\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.20589254783\n",
      "Accuracy on evaluation data: 8332 / 10000\n",
      "\n",
      "Epoch 77 training complete\n",
      "Cost on training data: 0.655233922158\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.20051547522\n",
      "Accuracy on evaluation data: 8332 / 10000\n",
      "\n",
      "Epoch 78 training complete\n",
      "Cost on training data: 0.650417277123\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19825892259\n",
      "Accuracy on evaluation data: 8316 / 10000\n",
      "\n",
      "Epoch 79 training complete\n",
      "Cost on training data: 0.643963391911\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.20691287863\n",
      "Accuracy on evaluation data: 8312 / 10000\n",
      "\n",
      "Epoch 80 training complete\n",
      "Cost on training data: 0.638189640657\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19550771682\n",
      "Accuracy on evaluation data: 8339 / 10000\n",
      "\n",
      "Epoch 81 training complete\n",
      "Cost on training data: 0.632608793411\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19620247892\n",
      "Accuracy on evaluation data: 8341 / 10000\n",
      "\n",
      "Epoch 82 training complete\n",
      "Cost on training data: 0.62727793512\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19399687558\n",
      "Accuracy on evaluation data: 8336 / 10000\n",
      "\n",
      "Epoch 83 training complete\n",
      "Cost on training data: 0.622141403991\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19408158573\n",
      "Accuracy on evaluation data: 8337 / 10000\n",
      "\n",
      "Epoch 84 training complete\n",
      "Cost on training data: 0.616258091032\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19299751841\n",
      "Accuracy on evaluation data: 8350 / 10000\n",
      "\n",
      "Epoch 85 training complete\n",
      "Cost on training data: 0.611057411807\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19045460183\n",
      "Accuracy on evaluation data: 8349 / 10000\n",
      "\n",
      "Epoch 86 training complete\n",
      "Cost on training data: 0.60574495833\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.18438554302\n",
      "Accuracy on evaluation data: 8347 / 10000\n",
      "\n",
      "Epoch 87 training complete\n",
      "Cost on training data: 0.600554774627\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.19339052968\n",
      "Accuracy on evaluation data: 8344 / 10000\n",
      "\n",
      "Epoch 88 training complete\n",
      "Cost on training data: 0.595232143254\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.18493252561\n",
      "Accuracy on evaluation data: 8357 / 10000\n",
      "\n",
      "Epoch 89 training complete\n",
      "Cost on training data: 0.590232971389\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17068949021\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 90 training complete\n",
      "Cost on training data: 0.584932689551\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17529889833\n",
      "Accuracy on evaluation data: 8371 / 10000\n",
      "\n",
      "Epoch 91 training complete\n",
      "Cost on training data: 0.580117467037\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17529922413\n",
      "Accuracy on evaluation data: 8368 / 10000\n",
      "\n",
      "Epoch 92 training complete\n",
      "Cost on training data: 0.575026012342\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17626083254\n",
      "Accuracy on evaluation data: 8369 / 10000\n",
      "\n",
      "Epoch 93 training complete\n",
      "Cost on training data: 0.570134470988\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17075996312\n",
      "Accuracy on evaluation data: 8378 / 10000\n",
      "\n",
      "Epoch 94 training complete\n",
      "Cost on training data: 0.5654250858\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.17600768825\n",
      "Accuracy on evaluation data: 8364 / 10000\n",
      "\n",
      "Epoch 95 training complete\n",
      "Cost on training data: 0.560694439995\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.16613152068\n",
      "Accuracy on evaluation data: 8384 / 10000\n",
      "\n",
      "Epoch 96 training complete\n",
      "Cost on training data: 0.555794101869\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.16469791847\n",
      "Accuracy on evaluation data: 8385 / 10000\n",
      "\n",
      "Epoch 97 training complete\n",
      "Cost on training data: 0.551359100682\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.16168557137\n",
      "Accuracy on evaluation data: 8386 / 10000\n",
      "\n",
      "Epoch 98 training complete\n",
      "Cost on training data: 0.546686020936\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.16313334168\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 99 training complete\n",
      "Cost on training data: 0.542011028119\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15703496194\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "\n",
      "Epoch 100 training complete\n",
      "Cost on training data: 0.537654442519\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15276356802\n",
      "Accuracy on evaluation data: 8405 / 10000\n",
      "\n",
      "Epoch 101 training complete\n",
      "Cost on training data: 0.533136011102\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15053747395\n",
      "Accuracy on evaluation data: 8400 / 10000\n",
      "\n",
      "Epoch 102 training complete\n",
      "Cost on training data: 0.528642691111\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15285626618\n",
      "Accuracy on evaluation data: 8403 / 10000\n",
      "\n",
      "Epoch 103 training complete\n",
      "Cost on training data: 0.52431824471\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15430137501\n",
      "Accuracy on evaluation data: 8402 / 10000\n",
      "\n",
      "Epoch 104 training complete\n",
      "Cost on training data: 0.520013596033\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15402551193\n",
      "Accuracy on evaluation data: 8410 / 10000\n",
      "\n",
      "Epoch 105 training complete\n",
      "Cost on training data: 0.515701715067\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.15064195543\n",
      "Accuracy on evaluation data: 8402 / 10000\n",
      "\n",
      "Epoch 106 training complete\n",
      "Cost on training data: 0.512003365162\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.14855223137\n",
      "Accuracy on evaluation data: 8404 / 10000\n",
      "\n",
      "Epoch 107 training complete\n",
      "Cost on training data: 0.507264889442\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.14849263154\n",
      "Accuracy on evaluation data: 8412 / 10000\n",
      "\n",
      "Epoch 108 training complete\n",
      "Cost on training data: 0.503163065368\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.14174591009\n",
      "Accuracy on evaluation data: 8410 / 10000\n",
      "\n",
      "Epoch 109 training complete\n",
      "Cost on training data: 0.499096344223\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.14832049705\n",
      "Accuracy on evaluation data: 8397 / 10000\n",
      "\n",
      "Epoch 110 training complete\n",
      "Cost on training data: 0.495312196288\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.13043404744\n",
      "Accuracy on evaluation data: 8422 / 10000\n",
      "\n",
      "Epoch 111 training complete\n",
      "Cost on training data: 0.49127975898\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.13450129126\n",
      "Accuracy on evaluation data: 8423 / 10000\n",
      "\n",
      "Epoch 112 training complete\n",
      "Cost on training data: 0.487023359836\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.12906948079\n",
      "Accuracy on evaluation data: 8432 / 10000\n",
      "\n",
      "Epoch 113 training complete\n",
      "Cost on training data: 0.483054979458\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.1332708766\n",
      "Accuracy on evaluation data: 8420 / 10000\n",
      "\n",
      "Epoch 114 training complete\n",
      "Cost on training data: 0.479103691455\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.12696898495\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "\n",
      "Epoch 115 training complete\n",
      "Cost on training data: 0.47556889573\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.13588902562\n",
      "Accuracy on evaluation data: 8426 / 10000\n",
      "\n",
      "Epoch 116 training complete\n",
      "Cost on training data: 0.471546727391\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.12376693307\n",
      "Accuracy on evaluation data: 8418 / 10000\n",
      "\n",
      "Epoch 117 training complete\n",
      "Cost on training data: 0.467664635834\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.12582091752\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "\n",
      "Epoch 118 training complete\n",
      "Cost on training data: 0.464229981481\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.12707944624\n",
      "Accuracy on evaluation data: 8417 / 10000\n",
      "\n",
      "Epoch 119 training complete\n",
      "Cost on training data: 0.460256215346\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.11866392089\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "\n",
      "Epoch 120 training complete\n",
      "Cost on training data: 0.456591046742\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.11694480739\n",
      "Accuracy on evaluation data: 8436 / 10000\n",
      "\n",
      "Epoch 121 training complete\n",
      "Cost on training data: 0.453042701277\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.11778990424\n",
      "Accuracy on evaluation data: 8436 / 10000\n",
      "\n",
      "Epoch 122 training complete\n",
      "Cost on training data: 0.449620190975\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.11563695886\n",
      "Accuracy on evaluation data: 8448 / 10000\n",
      "\n",
      "Epoch 123 training complete\n",
      "Cost on training data: 0.445850036967\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.11191566075\n",
      "Accuracy on evaluation data: 8441 / 10000\n",
      "\n",
      "Epoch 124 training complete\n",
      "Cost on training data: 0.442433128045\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.10912459248\n",
      "Accuracy on evaluation data: 8446 / 10000\n",
      "\n",
      "Epoch 125 training complete\n",
      "Cost on training data: 0.438820582995\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.10296728405\n",
      "Accuracy on evaluation data: 8451 / 10000\n",
      "\n",
      "Epoch 126 training complete\n",
      "Cost on training data: 0.435454837155\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.09825937332\n",
      "Accuracy on evaluation data: 8459 / 10000\n",
      "\n",
      "Epoch 127 training complete\n",
      "Cost on training data: 0.432247340019\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.10420309702\n",
      "Accuracy on evaluation data: 8446 / 10000\n",
      "\n",
      "Epoch 128 training complete\n",
      "Cost on training data: 0.428637563764\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.10328003625\n",
      "Accuracy on evaluation data: 8448 / 10000\n",
      "\n",
      "Epoch 129 training complete\n",
      "Cost on training data: 0.425280868546\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0982288501\n",
      "Accuracy on evaluation data: 8449 / 10000\n",
      "\n",
      "Epoch 130 training complete\n",
      "Cost on training data: 0.422255262008\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.09878672467\n",
      "Accuracy on evaluation data: 8450 / 10000\n",
      "\n",
      "Epoch 131 training complete\n",
      "Cost on training data: 0.418801777836\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.09868666048\n",
      "Accuracy on evaluation data: 8449 / 10000\n",
      "\n",
      "Epoch 132 training complete\n",
      "Cost on training data: 0.415527879716\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08979973685\n",
      "Accuracy on evaluation data: 8457 / 10000\n",
      "\n",
      "Epoch 133 training complete\n",
      "Cost on training data: 0.412264660696\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08737335705\n",
      "Accuracy on evaluation data: 8460 / 10000\n",
      "\n",
      "Epoch 134 training complete\n",
      "Cost on training data: 0.40909856162\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.09592393284\n",
      "Accuracy on evaluation data: 8446 / 10000\n",
      "\n",
      "Epoch 135 training complete\n",
      "Cost on training data: 0.406054020211\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08687004342\n",
      "Accuracy on evaluation data: 8464 / 10000\n",
      "\n",
      "Epoch 136 training complete\n",
      "Cost on training data: 0.402913824887\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08562217085\n",
      "Accuracy on evaluation data: 8458 / 10000\n",
      "\n",
      "Epoch 137 training complete\n",
      "Cost on training data: 0.39983115437\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08940734618\n",
      "Accuracy on evaluation data: 8460 / 10000\n",
      "\n",
      "Epoch 138 training complete\n",
      "Cost on training data: 0.396721946985\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08464857487\n",
      "Accuracy on evaluation data: 8465 / 10000\n",
      "\n",
      "Epoch 139 training complete\n",
      "Cost on training data: 0.393785879029\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.08987107894\n",
      "Accuracy on evaluation data: 8456 / 10000\n",
      "\n",
      "Epoch 140 training complete\n",
      "Cost on training data: 0.390883553678\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.080717671\n",
      "Accuracy on evaluation data: 8460 / 10000\n",
      "\n",
      "Epoch 141 training complete\n",
      "Cost on training data: 0.387875466806\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07567229276\n",
      "Accuracy on evaluation data: 8473 / 10000\n",
      "\n",
      "Epoch 142 training complete\n",
      "Cost on training data: 0.384855028258\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07715697168\n",
      "Accuracy on evaluation data: 8479 / 10000\n",
      "\n",
      "Epoch 143 training complete\n",
      "Cost on training data: 0.381975185227\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07410849887\n",
      "Accuracy on evaluation data: 8471 / 10000\n",
      "\n",
      "Epoch 144 training complete\n",
      "Cost on training data: 0.37923824552\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07681837824\n",
      "Accuracy on evaluation data: 8477 / 10000\n",
      "\n",
      "Epoch 145 training complete\n",
      "Cost on training data: 0.376303379969\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07372207828\n",
      "Accuracy on evaluation data: 8475 / 10000\n",
      "\n",
      "Epoch 146 training complete\n",
      "Cost on training data: 0.373631733958\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07390912547\n",
      "Accuracy on evaluation data: 8468 / 10000\n",
      "\n",
      "Epoch 147 training complete\n",
      "Cost on training data: 0.370786574505\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0676219806\n",
      "Accuracy on evaluation data: 8483 / 10000\n",
      "\n",
      "Epoch 148 training complete\n",
      "Cost on training data: 0.368039553644\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.06889740131\n",
      "Accuracy on evaluation data: 8481 / 10000\n",
      "\n",
      "Epoch 149 training complete\n",
      "Cost on training data: 0.365323602891\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.06569598183\n",
      "Accuracy on evaluation data: 8483 / 10000\n",
      "\n",
      "Epoch 150 training complete\n",
      "Cost on training data: 0.36268586018\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.07216609183\n",
      "Accuracy on evaluation data: 8472 / 10000\n",
      "\n",
      "Epoch 151 training complete\n",
      "Cost on training data: 0.359894719279\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.06053694338\n",
      "Accuracy on evaluation data: 8488 / 10000\n",
      "\n",
      "Epoch 152 training complete\n",
      "Cost on training data: 0.357226550779\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05801241938\n",
      "Accuracy on evaluation data: 8489 / 10000\n",
      "\n",
      "Epoch 153 training complete\n",
      "Cost on training data: 0.354656006513\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.06320104689\n",
      "Accuracy on evaluation data: 8486 / 10000\n",
      "\n",
      "Epoch 154 training complete\n",
      "Cost on training data: 0.352087584235\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05025938309\n",
      "Accuracy on evaluation data: 8503 / 10000\n",
      "\n",
      "Epoch 155 training complete\n",
      "Cost on training data: 0.349526619341\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05500442242\n",
      "Accuracy on evaluation data: 8497 / 10000\n",
      "\n",
      "Epoch 156 training complete\n",
      "Cost on training data: 0.347083845289\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04693818696\n",
      "Accuracy on evaluation data: 8506 / 10000\n",
      "\n",
      "Epoch 157 training complete\n",
      "Cost on training data: 0.34439653483\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04622468947\n",
      "Accuracy on evaluation data: 8521 / 10000\n",
      "\n",
      "Epoch 158 training complete\n",
      "Cost on training data: 0.34195552681\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05273841321\n",
      "Accuracy on evaluation data: 8499 / 10000\n",
      "\n",
      "Epoch 159 training complete\n",
      "Cost on training data: 0.339566162077\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05314839253\n",
      "Accuracy on evaluation data: 8500 / 10000\n",
      "\n",
      "Epoch 160 training complete\n",
      "Cost on training data: 0.33706142578\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.05005876784\n",
      "Accuracy on evaluation data: 8500 / 10000\n",
      "\n",
      "Epoch 161 training complete\n",
      "Cost on training data: 0.334565994946\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04576990042\n",
      "Accuracy on evaluation data: 8514 / 10000\n",
      "\n",
      "Epoch 162 training complete\n",
      "Cost on training data: 0.332110329572\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04560901584\n",
      "Accuracy on evaluation data: 8517 / 10000\n",
      "\n",
      "Epoch 163 training complete\n",
      "Cost on training data: 0.329764837992\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04442348393\n",
      "Accuracy on evaluation data: 8509 / 10000\n",
      "\n",
      "Epoch 164 training complete\n",
      "Cost on training data: 0.32744964678\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.04075151941\n",
      "Accuracy on evaluation data: 8526 / 10000\n",
      "\n",
      "Epoch 165 training complete\n",
      "Cost on training data: 0.325307273268\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03819034523\n",
      "Accuracy on evaluation data: 8526 / 10000\n",
      "\n",
      "Epoch 166 training complete\n",
      "Cost on training data: 0.322800179822\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03875777937\n",
      "Accuracy on evaluation data: 8520 / 10000\n",
      "\n",
      "Epoch 167 training complete\n",
      "Cost on training data: 0.320636911667\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03613934491\n",
      "Accuracy on evaluation data: 8527 / 10000\n",
      "\n",
      "Epoch 168 training complete\n",
      "Cost on training data: 0.318423672823\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03611606448\n",
      "Accuracy on evaluation data: 8515 / 10000\n",
      "\n",
      "Epoch 169 training complete\n",
      "Cost on training data: 0.316205265923\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0332315667\n",
      "Accuracy on evaluation data: 8523 / 10000\n",
      "\n",
      "Epoch 170 training complete\n",
      "Cost on training data: 0.313886769434\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02590381437\n",
      "Accuracy on evaluation data: 8542 / 10000\n",
      "\n",
      "Epoch 171 training complete\n",
      "Cost on training data: 0.311832227146\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03259836651\n",
      "Accuracy on evaluation data: 8521 / 10000\n",
      "\n",
      "Epoch 172 training complete\n",
      "Cost on training data: 0.309551912593\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03023542603\n",
      "Accuracy on evaluation data: 8532 / 10000\n",
      "\n",
      "Epoch 173 training complete\n",
      "Cost on training data: 0.307603791617\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.03495395529\n",
      "Accuracy on evaluation data: 8519 / 10000\n",
      "\n",
      "Epoch 174 training complete\n",
      "Cost on training data: 0.305308423073\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02729638079\n",
      "Accuracy on evaluation data: 8528 / 10000\n",
      "\n",
      "Epoch 175 training complete\n",
      "Cost on training data: 0.303185472314\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02180402912\n",
      "Accuracy on evaluation data: 8550 / 10000\n",
      "\n",
      "Epoch 176 training complete\n",
      "Cost on training data: 0.301236543861\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02639128433\n",
      "Accuracy on evaluation data: 8525 / 10000\n",
      "\n",
      "Epoch 177 training complete\n",
      "Cost on training data: 0.29908539556\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01794138766\n",
      "Accuracy on evaluation data: 8549 / 10000\n",
      "\n",
      "Epoch 178 training complete\n",
      "Cost on training data: 0.29710421233\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02547924563\n",
      "Accuracy on evaluation data: 8535 / 10000\n",
      "\n",
      "Epoch 179 training complete\n",
      "Cost on training data: 0.295188840618\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0155335631\n",
      "Accuracy on evaluation data: 8561 / 10000\n",
      "\n",
      "Epoch 180 training complete\n",
      "Cost on training data: 0.292968704554\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01698876223\n",
      "Accuracy on evaluation data: 8553 / 10000\n",
      "\n",
      "Epoch 181 training complete\n",
      "Cost on training data: 0.291155141088\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.02164553595\n",
      "Accuracy on evaluation data: 8542 / 10000\n",
      "\n",
      "Epoch 182 training complete\n",
      "Cost on training data: 0.28932630341\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01793001749\n",
      "Accuracy on evaluation data: 8546 / 10000\n",
      "\n",
      "Epoch 183 training complete\n",
      "Cost on training data: 0.287303751659\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0181069059\n",
      "Accuracy on evaluation data: 8551 / 10000\n",
      "\n",
      "Epoch 184 training complete\n",
      "Cost on training data: 0.285280785859\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01469828373\n",
      "Accuracy on evaluation data: 8565 / 10000\n",
      "\n",
      "Epoch 185 training complete\n",
      "Cost on training data: 0.283426292112\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01482545278\n",
      "Accuracy on evaluation data: 8548 / 10000\n",
      "\n",
      "Epoch 186 training complete\n",
      "Cost on training data: 0.281505955972\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01602345045\n",
      "Accuracy on evaluation data: 8549 / 10000\n",
      "\n",
      "Epoch 187 training complete\n",
      "Cost on training data: 0.279696309841\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01161863686\n",
      "Accuracy on evaluation data: 8558 / 10000\n",
      "\n",
      "Epoch 188 training complete\n",
      "Cost on training data: 0.277837763996\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.0120787995\n",
      "Accuracy on evaluation data: 8559 / 10000\n",
      "\n",
      "Epoch 189 training complete\n",
      "Cost on training data: 0.276127631962\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.01121154626\n",
      "Accuracy on evaluation data: 8578 / 10000\n",
      "\n",
      "Epoch 190 training complete\n",
      "Cost on training data: 0.274352692671\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.00443415131\n",
      "Accuracy on evaluation data: 8558 / 10000\n",
      "\n",
      "Epoch 191 training complete\n",
      "Cost on training data: 0.272464434564\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.00970571923\n",
      "Accuracy on evaluation data: 8558 / 10000\n",
      "\n",
      "Epoch 192 training complete\n",
      "Cost on training data: 0.270783615993\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.00555834498\n",
      "Accuracy on evaluation data: 8574 / 10000\n",
      "\n",
      "Epoch 193 training complete\n",
      "Cost on training data: 0.268887719162\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.996426020996\n",
      "Accuracy on evaluation data: 8575 / 10000\n",
      "\n",
      "Epoch 194 training complete\n",
      "Cost on training data: 0.267354867648\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.00101592205\n",
      "Accuracy on evaluation data: 8573 / 10000\n",
      "\n",
      "Epoch 195 training complete\n",
      "Cost on training data: 0.26547944976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.998125987868\n",
      "Accuracy on evaluation data: 8568 / 10000\n",
      "\n",
      "Epoch 196 training complete\n",
      "Cost on training data: 0.263818435155\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 1.00119566989\n",
      "Accuracy on evaluation data: 8579 / 10000\n",
      "\n",
      "Epoch 197 training complete\n",
      "Cost on training data: 0.262129679244\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.998332735513\n",
      "Accuracy on evaluation data: 8571 / 10000\n",
      "\n",
      "Epoch 198 training complete\n",
      "Cost on training data: 0.260369718136\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.994958039509\n",
      "Accuracy on evaluation data: 8589 / 10000\n",
      "\n",
      "Epoch 199 training complete\n",
      "Cost on training data: 0.258804297821\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.994092656812\n",
      "Accuracy on evaluation data: 8569 / 10000\n",
      "\n",
      "Epoch 200 training complete\n",
      "Cost on training data: 0.257416636844\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.990834522895\n",
      "Accuracy on evaluation data: 8588 / 10000\n",
      "\n",
      "Epoch 201 training complete\n",
      "Cost on training data: 0.255408147368\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.992052891813\n",
      "Accuracy on evaluation data: 8590 / 10000\n",
      "\n",
      "Epoch 202 training complete\n",
      "Cost on training data: 0.253900383505\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.991503027552\n",
      "Accuracy on evaluation data: 8593 / 10000\n",
      "\n",
      "Epoch 203 training complete\n",
      "Cost on training data: 0.252253507782\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.985374748443\n",
      "Accuracy on evaluation data: 8594 / 10000\n",
      "\n",
      "Epoch 204 training complete\n",
      "Cost on training data: 0.250847976485\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.99050073653\n",
      "Accuracy on evaluation data: 8599 / 10000\n",
      "\n",
      "Epoch 205 training complete\n",
      "Cost on training data: 0.249173460981\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.988707393643\n",
      "Accuracy on evaluation data: 8598 / 10000\n",
      "\n",
      "Epoch 206 training complete\n",
      "Cost on training data: 0.247721739959\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.98888477353\n",
      "Accuracy on evaluation data: 8592 / 10000\n",
      "\n",
      "Epoch 207 training complete\n",
      "Cost on training data: 0.246059953249\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.982955655318\n",
      "Accuracy on evaluation data: 8595 / 10000\n",
      "\n",
      "Epoch 208 training complete\n",
      "Cost on training data: 0.244631310987\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.985192644049\n",
      "Accuracy on evaluation data: 8597 / 10000\n",
      "\n",
      "Epoch 209 training complete\n",
      "Cost on training data: 0.243100271449\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.986622852407\n",
      "Accuracy on evaluation data: 8582 / 10000\n",
      "\n",
      "Epoch 210 training complete\n",
      "Cost on training data: 0.241627325171\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.980540834158\n",
      "Accuracy on evaluation data: 8605 / 10000\n",
      "\n",
      "Epoch 211 training complete\n",
      "Cost on training data: 0.240189937026\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.978788812777\n",
      "Accuracy on evaluation data: 8611 / 10000\n",
      "\n",
      "Epoch 212 training complete\n",
      "Cost on training data: 0.238689006713\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.978675774913\n",
      "Accuracy on evaluation data: 8611 / 10000\n",
      "\n",
      "Epoch 213 training complete\n",
      "Cost on training data: 0.237362560526\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.981788508309\n",
      "Accuracy on evaluation data: 8588 / 10000\n",
      "\n",
      "Epoch 214 training complete\n",
      "Cost on training data: 0.235891395062\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.978371477031\n",
      "Accuracy on evaluation data: 8606 / 10000\n",
      "\n",
      "Epoch 215 training complete\n",
      "Cost on training data: 0.234518932177\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.974139737271\n",
      "Accuracy on evaluation data: 8604 / 10000\n",
      "\n",
      "Epoch 216 training complete\n",
      "Cost on training data: 0.233024548018\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.97501143385\n",
      "Accuracy on evaluation data: 8606 / 10000\n",
      "\n",
      "Epoch 217 training complete\n",
      "Cost on training data: 0.231810332022\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.965842526837\n",
      "Accuracy on evaluation data: 8614 / 10000\n",
      "\n",
      "Epoch 218 training complete\n",
      "Cost on training data: 0.230228305629\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.970233625541\n",
      "Accuracy on evaluation data: 8611 / 10000\n",
      "\n",
      "Epoch 219 training complete\n",
      "Cost on training data: 0.228965807426\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.975860862106\n",
      "Accuracy on evaluation data: 8590 / 10000\n",
      "\n",
      "Epoch 220 training complete\n",
      "Cost on training data: 0.227785186296\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.968202059784\n",
      "Accuracy on evaluation data: 8594 / 10000\n",
      "\n",
      "Epoch 221 training complete\n",
      "Cost on training data: 0.226313844878\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.97035272941\n",
      "Accuracy on evaluation data: 8602 / 10000\n",
      "\n",
      "Epoch 222 training complete\n",
      "Cost on training data: 0.225096449444\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.97171947672\n",
      "Accuracy on evaluation data: 8602 / 10000\n",
      "\n",
      "Epoch 223 training complete\n",
      "Cost on training data: 0.223578390894\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.965738084506\n",
      "Accuracy on evaluation data: 8620 / 10000\n",
      "\n",
      "Epoch 224 training complete\n",
      "Cost on training data: 0.222379195078\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.961309373753\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "\n",
      "Epoch 225 training complete\n",
      "Cost on training data: 0.221233792976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.971407342844\n",
      "Accuracy on evaluation data: 8601 / 10000\n",
      "\n",
      "Epoch 226 training complete\n",
      "Cost on training data: 0.220128728736\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.959950998964\n",
      "Accuracy on evaluation data: 8617 / 10000\n",
      "\n",
      "Epoch 227 training complete\n",
      "Cost on training data: 0.21858249138\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.961632789855\n",
      "Accuracy on evaluation data: 8614 / 10000\n",
      "\n",
      "Epoch 228 training complete\n",
      "Cost on training data: 0.217418708213\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.958534078553\n",
      "Accuracy on evaluation data: 8618 / 10000\n",
      "\n",
      "Epoch 229 training complete\n",
      "Cost on training data: 0.216126022158\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.959571049508\n",
      "Accuracy on evaluation data: 8627 / 10000\n",
      "\n",
      "Epoch 230 training complete\n",
      "Cost on training data: 0.214898298277\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.95964578354\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "\n",
      "Epoch 231 training complete\n",
      "Cost on training data: 0.213749233192\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.958635553907\n",
      "Accuracy on evaluation data: 8615 / 10000\n",
      "\n",
      "Epoch 232 training complete\n",
      "Cost on training data: 0.212529452143\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.957641145762\n",
      "Accuracy on evaluation data: 8611 / 10000\n",
      "\n",
      "Epoch 233 training complete\n",
      "Cost on training data: 0.211268161667\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.953494321576\n",
      "Accuracy on evaluation data: 8624 / 10000\n",
      "\n",
      "Epoch 234 training complete\n",
      "Cost on training data: 0.210164562938\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.94956863367\n",
      "Accuracy on evaluation data: 8637 / 10000\n",
      "\n",
      "Epoch 235 training complete\n",
      "Cost on training data: 0.20911768356\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.95442415803\n",
      "Accuracy on evaluation data: 8611 / 10000\n",
      "\n",
      "Epoch 236 training complete\n",
      "Cost on training data: 0.207930151439\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.963556838576\n",
      "Accuracy on evaluation data: 8604 / 10000\n",
      "\n",
      "Epoch 237 training complete\n",
      "Cost on training data: 0.206700007698\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.949654569407\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "\n",
      "Epoch 238 training complete\n",
      "Cost on training data: 0.205689705774\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.949729255005\n",
      "Accuracy on evaluation data: 8625 / 10000\n",
      "\n",
      "Epoch 239 training complete\n",
      "Cost on training data: 0.204612422836\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.950565797275\n",
      "Accuracy on evaluation data: 8617 / 10000\n",
      "\n",
      "Epoch 240 training complete\n",
      "Cost on training data: 0.203813499523\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.945711068081\n",
      "Accuracy on evaluation data: 8637 / 10000\n",
      "\n",
      "Epoch 241 training complete\n",
      "Cost on training data: 0.202304289692\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.946567307198\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "\n",
      "Epoch 242 training complete\n",
      "Cost on training data: 0.20125502223\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.947149954979\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "\n",
      "Epoch 243 training complete\n",
      "Cost on training data: 0.200245860662\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.94472900787\n",
      "Accuracy on evaluation data: 8637 / 10000\n",
      "\n",
      "Epoch 244 training complete\n",
      "Cost on training data: 0.199279389054\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.94970436439\n",
      "Accuracy on evaluation data: 8632 / 10000\n",
      "\n",
      "Epoch 245 training complete\n",
      "Cost on training data: 0.198384876519\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.944658272815\n",
      "Accuracy on evaluation data: 8645 / 10000\n",
      "\n",
      "Epoch 246 training complete\n",
      "Cost on training data: 0.197285996917\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.93941359228\n",
      "Accuracy on evaluation data: 8633 / 10000\n",
      "\n",
      "Epoch 247 training complete\n",
      "Cost on training data: 0.196007040272\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.945558191972\n",
      "Accuracy on evaluation data: 8629 / 10000\n",
      "\n",
      "Epoch 248 training complete\n",
      "Cost on training data: 0.195107186459\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.938697262288\n",
      "Accuracy on evaluation data: 8638 / 10000\n",
      "\n",
      "Epoch 249 training complete\n",
      "Cost on training data: 0.194094280307\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.936986989821\n",
      "Accuracy on evaluation data: 8638 / 10000\n",
      "\n",
      "Epoch 250 training complete\n",
      "Cost on training data: 0.19301639416\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.94225969738\n",
      "Accuracy on evaluation data: 8625 / 10000\n",
      "\n",
      "Epoch 251 training complete\n",
      "Cost on training data: 0.192016002779\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.940825686908\n",
      "Accuracy on evaluation data: 8637 / 10000\n",
      "\n",
      "Epoch 252 training complete\n",
      "Cost on training data: 0.191024126614\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.936990042685\n",
      "Accuracy on evaluation data: 8635 / 10000\n",
      "\n",
      "Epoch 253 training complete\n",
      "Cost on training data: 0.189978753703\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.939439473346\n",
      "Accuracy on evaluation data: 8625 / 10000\n",
      "\n",
      "Epoch 254 training complete\n",
      "Cost on training data: 0.189071590701\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.93715105444\n",
      "Accuracy on evaluation data: 8643 / 10000\n",
      "\n",
      "Epoch 255 training complete\n",
      "Cost on training data: 0.188049468643\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.932579665856\n",
      "Accuracy on evaluation data: 8645 / 10000\n",
      "\n",
      "Epoch 256 training complete\n",
      "Cost on training data: 0.187149058122\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.936851413787\n",
      "Accuracy on evaluation data: 8635 / 10000\n",
      "\n",
      "Epoch 257 training complete\n",
      "Cost on training data: 0.186280247191\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.934099939589\n",
      "Accuracy on evaluation data: 8644 / 10000\n",
      "\n",
      "Epoch 258 training complete\n",
      "Cost on training data: 0.185273833815\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.935105068192\n",
      "Accuracy on evaluation data: 8639 / 10000\n",
      "\n",
      "Epoch 259 training complete\n",
      "Cost on training data: 0.184390874374\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.931322516069\n",
      "Accuracy on evaluation data: 8648 / 10000\n",
      "\n",
      "Epoch 260 training complete\n",
      "Cost on training data: 0.183563935844\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.934133812019\n",
      "Accuracy on evaluation data: 8650 / 10000\n",
      "\n",
      "Epoch 261 training complete\n",
      "Cost on training data: 0.182840786249\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.930748090825\n",
      "Accuracy on evaluation data: 8654 / 10000\n",
      "\n",
      "Epoch 262 training complete\n",
      "Cost on training data: 0.181702607337\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.925917182345\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "\n",
      "Epoch 263 training complete\n",
      "Cost on training data: 0.180903750909\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.928175343274\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "\n",
      "Epoch 264 training complete\n",
      "Cost on training data: 0.180038600792\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.931542886668\n",
      "Accuracy on evaluation data: 8635 / 10000\n",
      "\n",
      "Epoch 265 training complete\n",
      "Cost on training data: 0.179075351576\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.92907488678\n",
      "Accuracy on evaluation data: 8655 / 10000\n",
      "\n",
      "Epoch 266 training complete\n",
      "Cost on training data: 0.178321195924\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.927064688521\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "\n",
      "Epoch 267 training complete\n",
      "Cost on training data: 0.177477655694\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.921220417854\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "\n",
      "Epoch 268 training complete\n",
      "Cost on training data: 0.176690344192\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.923520755838\n",
      "Accuracy on evaluation data: 8645 / 10000\n",
      "\n",
      "Epoch 269 training complete\n",
      "Cost on training data: 0.1757641761\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.922193169418\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "\n",
      "Epoch 270 training complete\n",
      "Cost on training data: 0.175242417442\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.926715462489\n",
      "Accuracy on evaluation data: 8648 / 10000\n",
      "\n",
      "Epoch 271 training complete\n",
      "Cost on training data: 0.174043233306\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.923636343839\n",
      "Accuracy on evaluation data: 8652 / 10000\n",
      "\n",
      "Epoch 272 training complete\n",
      "Cost on training data: 0.173378421834\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.920090247096\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "\n",
      "Epoch 273 training complete\n",
      "Cost on training data: 0.172654385156\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.92548625784\n",
      "Accuracy on evaluation data: 8648 / 10000\n",
      "\n",
      "Epoch 274 training complete\n",
      "Cost on training data: 0.171784542497\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.91862942868\n",
      "Accuracy on evaluation data: 8677 / 10000\n",
      "\n",
      "Epoch 275 training complete\n",
      "Cost on training data: 0.170894155625\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.918050781548\n",
      "Accuracy on evaluation data: 8667 / 10000\n",
      "\n",
      "Epoch 276 training complete\n",
      "Cost on training data: 0.170152837182\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.918806009108\n",
      "Accuracy on evaluation data: 8665 / 10000\n",
      "\n",
      "Epoch 277 training complete\n",
      "Cost on training data: 0.169396617148\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.922833710245\n",
      "Accuracy on evaluation data: 8657 / 10000\n",
      "\n",
      "Epoch 278 training complete\n",
      "Cost on training data: 0.168616569275\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.911996151085\n",
      "Accuracy on evaluation data: 8679 / 10000\n",
      "\n",
      "Epoch 279 training complete\n",
      "Cost on training data: 0.168085725853\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.919808381926\n",
      "Accuracy on evaluation data: 8674 / 10000\n",
      "\n",
      "Epoch 280 training complete\n",
      "Cost on training data: 0.16741982124\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.921695862947\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "\n",
      "Epoch 281 training complete\n",
      "Cost on training data: 0.16647932922\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.918390550636\n",
      "Accuracy on evaluation data: 8668 / 10000\n",
      "\n",
      "Epoch 282 training complete\n",
      "Cost on training data: 0.165548910105\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.914058165463\n",
      "Accuracy on evaluation data: 8679 / 10000\n",
      "\n",
      "Epoch 283 training complete\n",
      "Cost on training data: 0.165469790715\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.922018737106\n",
      "Accuracy on evaluation data: 8661 / 10000\n",
      "\n",
      "Epoch 284 training complete\n",
      "Cost on training data: 0.164241720104\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.906827772824\n",
      "Accuracy on evaluation data: 8676 / 10000\n",
      "\n",
      "Epoch 285 training complete\n",
      "Cost on training data: 0.163703804329\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.914912034396\n",
      "Accuracy on evaluation data: 8659 / 10000\n",
      "\n",
      "Epoch 286 training complete\n",
      "Cost on training data: 0.162872776363\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.911907466619\n",
      "Accuracy on evaluation data: 8674 / 10000\n",
      "\n",
      "Epoch 287 training complete\n",
      "Cost on training data: 0.162298594835\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.909780890316\n",
      "Accuracy on evaluation data: 8677 / 10000\n",
      "\n",
      "Epoch 288 training complete\n",
      "Cost on training data: 0.161400846442\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.911128157537\n",
      "Accuracy on evaluation data: 8683 / 10000\n",
      "\n",
      "Epoch 289 training complete\n",
      "Cost on training data: 0.160642718321\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.91259714894\n",
      "Accuracy on evaluation data: 8679 / 10000\n",
      "\n",
      "Epoch 290 training complete\n",
      "Cost on training data: 0.160032596808\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.907102150559\n",
      "Accuracy on evaluation data: 8682 / 10000\n",
      "\n",
      "Epoch 291 training complete\n",
      "Cost on training data: 0.159341165313\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.916681520657\n",
      "Accuracy on evaluation data: 8674 / 10000\n",
      "\n",
      "Epoch 292 training complete\n",
      "Cost on training data: 0.158565979595\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.909258097989\n",
      "Accuracy on evaluation data: 8675 / 10000\n",
      "\n",
      "Epoch 293 training complete\n",
      "Cost on training data: 0.158117172721\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.904333577963\n",
      "Accuracy on evaluation data: 8702 / 10000\n",
      "\n",
      "Epoch 294 training complete\n",
      "Cost on training data: 0.157436001367\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.910075035179\n",
      "Accuracy on evaluation data: 8677 / 10000\n",
      "\n",
      "Epoch 295 training complete\n",
      "Cost on training data: 0.156685696618\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.908295393481\n",
      "Accuracy on evaluation data: 8672 / 10000\n",
      "\n",
      "Epoch 296 training complete\n",
      "Cost on training data: 0.15604514475\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.903910693996\n",
      "Accuracy on evaluation data: 8696 / 10000\n",
      "\n",
      "Epoch 297 training complete\n",
      "Cost on training data: 0.155301544824\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.903221339857\n",
      "Accuracy on evaluation data: 8697 / 10000\n",
      "\n",
      "Epoch 298 training complete\n",
      "Cost on training data: 0.15494370082\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.904716068966\n",
      "Accuracy on evaluation data: 8687 / 10000\n",
      "\n",
      "Epoch 299 training complete\n",
      "Cost on training data: 0.154275304413\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.908905087883\n",
      "Accuracy on evaluation data: 8691 / 10000\n",
      "\n",
      "Epoch 300 training complete\n",
      "Cost on training data: 0.15360404055\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.903846619528\n",
      "Accuracy on evaluation data: 8681 / 10000\n",
      "\n",
      "Epoch 301 training complete\n",
      "Cost on training data: 0.152895251355\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.901170723615\n",
      "Accuracy on evaluation data: 8703 / 10000\n",
      "\n",
      "Epoch 302 training complete\n",
      "Cost on training data: 0.152230560938\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.900941565965\n",
      "Accuracy on evaluation data: 8702 / 10000\n",
      "\n",
      "Epoch 303 training complete\n",
      "Cost on training data: 0.151715657248\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.894088978312\n",
      "Accuracy on evaluation data: 8709 / 10000\n",
      "\n",
      "Epoch 304 training complete\n",
      "Cost on training data: 0.151327802343\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 0.900046742924\n",
      "Accuracy on evaluation data: 8697 / 10000\n",
      "\n",
      "Epoch 305 training complete\n",
      "Cost on training data: 0.150520323013\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8021c116656e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m net.SGD(training_data[:1000], 400, 10, 0.5,evaluation_data=test_data, lmbda = 0.1,\n\u001b[0;32m      7\u001b[0m         \u001b[0mmonitor_evaluation_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor_evaluation_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         monitor_training_cost=True, monitor_training_accuracy=True)\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, lmbda, evaluation_data, monitor_evaluation_cost, monitor_evaluation_accuracy, monitor_training_cost, monitor_training_accuracy)\u001b[0m\n\u001b[0;32m    171\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Cost on training data: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmonitor_training_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m                 \u001b[0mtraining_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                 print \"Accuracy on training data: {} / {}\".format(\n",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, data, convert)\u001b[0m\n\u001b[0;32m    270\u001b[0m             results = [(np.argmax(self.feedforward(x)), y)\n\u001b[0;32m    271\u001b[0m                         for (x, y) in data]\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtotal_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kail\\Documents\\Cours\\E5\\DRIO5201Arnaud\\src\\network2.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m((x, y))\u001b[0m\n\u001b[0;32m    270\u001b[0m             results = [(np.argmax(self.feedforward(x)), y)\n\u001b[0;32m    271\u001b[0m                         for (x, y) in data]\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtotal_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mnist_loader \n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper() \n",
    "import network2 \n",
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data[:1000], 400, 10, 0.5,evaluation_data=test_data, lmbda = 0.1,\n",
    "        monitor_evaluation_cost=True, monitor_evaluation_accuracy=True,\n",
    "        monitor_training_cost=True, monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on training data: 45597 / 50000\n",
      "Accuracy on evaluation data: 9123 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on training data: 46868 / 50000\n",
      "Accuracy on evaluation data: 9357 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on training data: 47237 / 50000\n",
      "Accuracy on evaluation data: 9425 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on training data: 47567 / 50000\n",
      "Accuracy on evaluation data: 9472 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on training data: 47542 / 50000\n",
      "Accuracy on evaluation data: 9431 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on training data: 47833 / 50000\n",
      "Accuracy on evaluation data: 9513 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on training data: 48032 / 50000\n",
      "Accuracy on evaluation data: 9545 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on training data: 48033 / 50000\n",
      "Accuracy on evaluation data: 9525 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on training data: 47754 / 50000\n",
      "Accuracy on evaluation data: 9491 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on training data: 48242 / 50000\n",
      "Accuracy on evaluation data: 9598 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on training data: 48273 / 50000\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on training data: 48336 / 50000\n",
      "Accuracy on evaluation data: 9587 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on training data: 47943 / 50000\n",
      "Accuracy on evaluation data: 9510 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on training data: 48311 / 50000\n",
      "Accuracy on evaluation data: 9590 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on training data: 48348 / 50000\n",
      "Accuracy on evaluation data: 9601 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on training data: 48413 / 50000\n",
      "Accuracy on evaluation data: 9588 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on training data: 48248 / 50000\n",
      "Accuracy on evaluation data: 9578 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on training data: 48227 / 50000\n",
      "Accuracy on evaluation data: 9552 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on training data: 48198 / 50000\n",
      "Accuracy on evaluation data: 9555 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on training data: 48360 / 50000\n",
      "Accuracy on evaluation data: 9587 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on training data: 48556 / 50000\n",
      "Accuracy on evaluation data: 9633 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on training data: 48229 / 50000\n",
      "Accuracy on evaluation data: 9562 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on training data: 48359 / 50000\n",
      "Accuracy on evaluation data: 9583 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on training data: 48445 / 50000\n",
      "Accuracy on evaluation data: 9618 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on training data: 48494 / 50000\n",
      "Accuracy on evaluation data: 9627 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on training data: 48369 / 50000\n",
      "Accuracy on evaluation data: 9587 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on training data: 48215 / 50000\n",
      "Accuracy on evaluation data: 9579 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on training data: 48447 / 50000\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on training data: 48200 / 50000\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on training data: 48005 / 50000\n",
      "Accuracy on evaluation data: 9502 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9123,\n",
       "  9357,\n",
       "  9425,\n",
       "  9472,\n",
       "  9431,\n",
       "  9513,\n",
       "  9545,\n",
       "  9525,\n",
       "  9491,\n",
       "  9598,\n",
       "  9581,\n",
       "  9587,\n",
       "  9510,\n",
       "  9590,\n",
       "  9601,\n",
       "  9588,\n",
       "  9578,\n",
       "  9552,\n",
       "  9555,\n",
       "  9587,\n",
       "  9633,\n",
       "  9562,\n",
       "  9583,\n",
       "  9618,\n",
       "  9627,\n",
       "  9587,\n",
       "  9579,\n",
       "  9580,\n",
       "  9580,\n",
       "  9502],\n",
       " [],\n",
       " [45597,\n",
       "  46868,\n",
       "  47237,\n",
       "  47567,\n",
       "  47542,\n",
       "  47833,\n",
       "  48032,\n",
       "  48033,\n",
       "  47754,\n",
       "  48242,\n",
       "  48273,\n",
       "  48336,\n",
       "  47943,\n",
       "  48311,\n",
       "  48348,\n",
       "  48413,\n",
       "  48248,\n",
       "  48227,\n",
       "  48198,\n",
       "  48360,\n",
       "  48556,\n",
       "  48229,\n",
       "  48359,\n",
       "  48445,\n",
       "  48494,\n",
       "  48369,\n",
       "  48215,\n",
       "  48447,\n",
       "  48200,\n",
       "  48005])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5,\n",
    "        evaluation_data=test_data, lmbda = 5.0,\n",
    "        monitor_evaluation_accuracy=True, monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9406 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9507 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9683 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9695 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9699 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9738 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9737 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9696 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9698 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9708 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9737 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9726 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9725 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9725 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9727 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9752 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9726 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9755 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9756 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9720 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9781 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9729 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9782 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9775 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9760 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9729 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9754 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9774 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9772 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9406,\n",
       "  9507,\n",
       "  9638,\n",
       "  9683,\n",
       "  9695,\n",
       "  9699,\n",
       "  9738,\n",
       "  9737,\n",
       "  9696,\n",
       "  9698,\n",
       "  9708,\n",
       "  9737,\n",
       "  9726,\n",
       "  9725,\n",
       "  9725,\n",
       "  9727,\n",
       "  9752,\n",
       "  9726,\n",
       "  9755,\n",
       "  9756,\n",
       "  9720,\n",
       "  9781,\n",
       "  9729,\n",
       "  9782,\n",
       "  9775,\n",
       "  9760,\n",
       "  9729,\n",
       "  9754,\n",
       "  9774,\n",
       "  9772],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5, lmbda=5.0,\n",
    "        evaluation_data=validation_data,\n",
    "        monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9293 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9428 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9477 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9516 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9539 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9595 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9590 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9614 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9618 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9607 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9643 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9625 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9649 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9644 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9658 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9645 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9662 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9664 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9639 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9669 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9671 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9671 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9293,\n",
       "  9428,\n",
       "  9477,\n",
       "  9516,\n",
       "  9539,\n",
       "  9572,\n",
       "  9581,\n",
       "  9595,\n",
       "  9590,\n",
       "  9614,\n",
       "  9617,\n",
       "  9618,\n",
       "  9607,\n",
       "  9617,\n",
       "  9643,\n",
       "  9617,\n",
       "  9625,\n",
       "  9649,\n",
       "  9644,\n",
       "  9658,\n",
       "  9641,\n",
       "  9645,\n",
       "  9638,\n",
       "  9662,\n",
       "  9664,\n",
       "  9639,\n",
       "  9669,\n",
       "  9670,\n",
       "  9671,\n",
       "  9671],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0,\n",
    "            evaluation_data=validation_data,\n",
    "            monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 0.475760897816\n",
      "Accuracy on training data: 47069 / 50000\n",
      "Cost on evaluation data: 0.788086647832\n",
      "Accuracy on evaluation data: 9436 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 0.448170197545\n",
      "Accuracy on training data: 47485 / 50000\n",
      "Cost on evaluation data: 0.862582854958\n",
      "Accuracy on evaluation data: 9492 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 0.434793024323\n",
      "Accuracy on training data: 47711 / 50000\n",
      "Cost on evaluation data: 0.903366013817\n",
      "Accuracy on evaluation data: 9498 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.455624164815\n",
      "Accuracy on training data: 47582 / 50000\n",
      "Cost on evaluation data: 0.95958768833\n",
      "Accuracy on evaluation data: 9497 / 10000\n",
      "\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.407773068196\n",
      "Accuracy on training data: 48021 / 50000\n",
      "Cost on evaluation data: 0.929492915337\n",
      "Accuracy on evaluation data: 9560 / 10000\n",
      "\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.400701979281\n",
      "Accuracy on training data: 48149 / 50000\n",
      "Cost on evaluation data: 0.929265290165\n",
      "Accuracy on evaluation data: 9575 / 10000\n",
      "\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.44011510503\n",
      "Accuracy on training data: 47824 / 50000\n",
      "Cost on evaluation data: 0.978462259804\n",
      "Accuracy on evaluation data: 9515 / 10000\n",
      "\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.417894017177\n",
      "Accuracy on training data: 48119 / 50000\n",
      "Cost on evaluation data: 0.953130478081\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.398765733782\n",
      "Accuracy on training data: 48209 / 50000\n",
      "Cost on evaluation data: 0.947297911542\n",
      "Accuracy on evaluation data: 9585 / 10000\n",
      "\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.403075733755\n",
      "Accuracy on training data: 48144 / 50000\n",
      "Cost on evaluation data: 0.959839751712\n",
      "Accuracy on evaluation data: 9551 / 10000\n",
      "\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.464353742872\n",
      "Accuracy on training data: 47628 / 50000\n",
      "Cost on evaluation data: 1.03597187508\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.414461687695\n",
      "Accuracy on training data: 48007 / 50000\n",
      "Cost on evaluation data: 0.968750881759\n",
      "Accuracy on evaluation data: 9544 / 10000\n",
      "\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.38062479198\n",
      "Accuracy on training data: 48332 / 50000\n",
      "Cost on evaluation data: 0.943770803528\n",
      "Accuracy on evaluation data: 9589 / 10000\n",
      "\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.374545270326\n",
      "Accuracy on training data: 48350 / 50000\n",
      "Cost on evaluation data: 0.932590366937\n",
      "Accuracy on evaluation data: 9609 / 10000\n",
      "\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.383554910127\n",
      "Accuracy on training data: 48269 / 50000\n",
      "Cost on evaluation data: 0.94462371113\n",
      "Accuracy on evaluation data: 9594 / 10000\n",
      "\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.373707422709\n",
      "Accuracy on training data: 48389 / 50000\n",
      "Cost on evaluation data: 0.949138782646\n",
      "Accuracy on evaluation data: 9606 / 10000\n",
      "\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.416760721943\n",
      "Accuracy on training data: 48058 / 50000\n",
      "Cost on evaluation data: 0.986557633509\n",
      "Accuracy on evaluation data: 9550 / 10000\n",
      "\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.386473925259\n",
      "Accuracy on training data: 48201 / 50000\n",
      "Cost on evaluation data: 0.965055528643\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.415128850572\n",
      "Accuracy on training data: 48041 / 50000\n",
      "Cost on evaluation data: 0.986525145916\n",
      "Accuracy on evaluation data: 9559 / 10000\n",
      "\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.396385971802\n",
      "Accuracy on training data: 48144 / 50000\n",
      "Cost on evaluation data: 0.966846121725\n",
      "Accuracy on evaluation data: 9576 / 10000\n",
      "\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.400378809416\n",
      "Accuracy on training data: 48161 / 50000\n",
      "Cost on evaluation data: 0.974872325197\n",
      "Accuracy on evaluation data: 9567 / 10000\n",
      "\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.383285883264\n",
      "Accuracy on training data: 48297 / 50000\n",
      "Cost on evaluation data: 0.962091677123\n",
      "Accuracy on evaluation data: 9606 / 10000\n",
      "\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.384941409233\n",
      "Accuracy on training data: 48265 / 50000\n",
      "Cost on evaluation data: 0.953575933712\n",
      "Accuracy on evaluation data: 9613 / 10000\n",
      "\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.396447548869\n",
      "Accuracy on training data: 48220 / 50000\n",
      "Cost on evaluation data: 0.965224659513\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.37130339523\n",
      "Accuracy on training data: 48311 / 50000\n",
      "Cost on evaluation data: 0.957275897075\n",
      "Accuracy on evaluation data: 9587 / 10000\n",
      "\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.375222674443\n",
      "Accuracy on training data: 48349 / 50000\n",
      "Cost on evaluation data: 0.948204273532\n",
      "Accuracy on evaluation data: 9604 / 10000\n",
      "\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.373170002222\n",
      "Accuracy on training data: 48367 / 50000\n",
      "Cost on evaluation data: 0.944474269477\n",
      "Accuracy on evaluation data: 9601 / 10000\n",
      "\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.37884037896\n",
      "Accuracy on training data: 48357 / 50000\n",
      "Cost on evaluation data: 0.948867249911\n",
      "Accuracy on evaluation data: 9592 / 10000\n",
      "\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.3823058967\n",
      "Accuracy on training data: 48352 / 50000\n",
      "Cost on evaluation data: 0.969114128575\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.373090681572\n",
      "Accuracy on training data: 48393 / 50000\n",
      "Cost on evaluation data: 0.953166291674\n",
      "Accuracy on evaluation data: 9615 / 10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7880866478319567,\n",
       "  0.8625828549579978,\n",
       "  0.90336601381674875,\n",
       "  0.959587688330239,\n",
       "  0.92949291533743406,\n",
       "  0.92926529016464399,\n",
       "  0.97846225980416224,\n",
       "  0.95313047808080831,\n",
       "  0.94729791154201881,\n",
       "  0.95983975171154734,\n",
       "  1.0359718750753271,\n",
       "  0.96875088175919166,\n",
       "  0.94377080352810616,\n",
       "  0.93259036693719921,\n",
       "  0.94462371113016863,\n",
       "  0.94913878264627038,\n",
       "  0.986557633508515,\n",
       "  0.96505552864254063,\n",
       "  0.98652514591620988,\n",
       "  0.96684612172510942,\n",
       "  0.97487232519711964,\n",
       "  0.96209167712255117,\n",
       "  0.95357593371202687,\n",
       "  0.96522465951347913,\n",
       "  0.95727589707521266,\n",
       "  0.94820427353213965,\n",
       "  0.94447426947694713,\n",
       "  0.94886724991080262,\n",
       "  0.96911412857539858,\n",
       "  0.95316629167398881],\n",
       " [9436,\n",
       "  9492,\n",
       "  9498,\n",
       "  9497,\n",
       "  9560,\n",
       "  9575,\n",
       "  9515,\n",
       "  9581,\n",
       "  9585,\n",
       "  9551,\n",
       "  9455,\n",
       "  9544,\n",
       "  9589,\n",
       "  9609,\n",
       "  9594,\n",
       "  9606,\n",
       "  9550,\n",
       "  9580,\n",
       "  9559,\n",
       "  9576,\n",
       "  9567,\n",
       "  9606,\n",
       "  9613,\n",
       "  9572,\n",
       "  9587,\n",
       "  9604,\n",
       "  9601,\n",
       "  9592,\n",
       "  9577,\n",
       "  9615],\n",
       " [0.47576089781557829,\n",
       "  0.44817019754469789,\n",
       "  0.4347930243229165,\n",
       "  0.45562416481529477,\n",
       "  0.40777306819632464,\n",
       "  0.40070197928105705,\n",
       "  0.44011510502990964,\n",
       "  0.41789401717671903,\n",
       "  0.39876573378222047,\n",
       "  0.40307573375471184,\n",
       "  0.46435374287168063,\n",
       "  0.41446168769484343,\n",
       "  0.38062479197992105,\n",
       "  0.37454527032565582,\n",
       "  0.38355491012667831,\n",
       "  0.37370742270937829,\n",
       "  0.41676072194274738,\n",
       "  0.38647392525914054,\n",
       "  0.41512885057231608,\n",
       "  0.39638597180161905,\n",
       "  0.40037880941622273,\n",
       "  0.38328588326384727,\n",
       "  0.38494140923261522,\n",
       "  0.39644754886930023,\n",
       "  0.37130339523046496,\n",
       "  0.37522267444289392,\n",
       "  0.37317000222164259,\n",
       "  0.37884037896030998,\n",
       "  0.3823058967001205,\n",
       "  0.37309068157152181],\n",
       " [47069,\n",
       "  47485,\n",
       "  47711,\n",
       "  47582,\n",
       "  48021,\n",
       "  48149,\n",
       "  47824,\n",
       "  48119,\n",
       "  48209,\n",
       "  48144,\n",
       "  47628,\n",
       "  48007,\n",
       "  48332,\n",
       "  48350,\n",
       "  48269,\n",
       "  48389,\n",
       "  48058,\n",
       "  48201,\n",
       "  48041,\n",
       "  48144,\n",
       "  48161,\n",
       "  48297,\n",
       "  48265,\n",
       "  48220,\n",
       "  48311,\n",
       "  48349,\n",
       "  48367,\n",
       "  48357,\n",
       "  48352,\n",
       "  48393])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.SGD(training_data, 30, 10, 0.5, lmbda = 5.0,\n",
    "        evaluation_data=validation_data,\n",
    "        monitor_evaluation_accuracy=True,\n",
    "        monitor_evaluation_cost=True,\n",
    "        monitor_training_accuracy=True,\n",
    "        monitor_training_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Theano : http://stackoverflow.com/questions/33687103/how-to-install-theano-on-anaconda-python-2-7-x64-on-windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnaud\\Anaconda3\\envs\\py27\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with a CPU.  If this is not desired, then the modify network3.py to set\n",
      "the GPU flag to True.\n",
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 92.36%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 91.72%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 94.43%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 93.80%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 95.56%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 94.93%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 96.07%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 95.55%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 96.40%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.07%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 96.64%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.36%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 96.74%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.60%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 96.90%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.77%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 97.01%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.89%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 97.11%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.01%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 97.14%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.09%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 97.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.17%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 97.18%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 97.22%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.30%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 97.23%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.33%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 97.32%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.39%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 97.33%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.41%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 97.37%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.45%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 97.41%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.48%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 97.46%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.49%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 97.45%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 97.45%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 97.43%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 97.43%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 97.47%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.62%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 97.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.62%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 97.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.63%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 97.48%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 97.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.66%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 97.46%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 97.46%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 97.47%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 97.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.72%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 97.43%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 97.44%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 97.46%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 97.47%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 97.48%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 97.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 97.49%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.71%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.74%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 97.50%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.72%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 97.51%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 97.53%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.72%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 97.52%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.78%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.76%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.76%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.74%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 97.54%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 97.55%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 97.57%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.73%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 97.56%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 97.56%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 97.56%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 97.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.74%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 97.58%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.75%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 97.57%\n",
      "Finished training network.\n",
      "Best validation accuracy of 97.58% obtained at iteration 294999\n",
      "Corresponding test accuracy of 97.75%\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        FullyConnectedLayer(n_in=784, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 87.34%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 86.37%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 96.62%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 96.24%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 97.62%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.15%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 97.97%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.77%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.21%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.10%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.41%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.24%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.45%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.38%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c8c1a222ae22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n\u001b[1;32m     10\u001b[0m net.SGD(training_data, 60, mini_batch_size, 0.1, \n\u001b[0;32m---> 11\u001b[0;31m             validation_data, test_data)  \n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Arnaud\\Desktop\\ESIEE\\E5\\DRIO-5201A\\neural-networks-and-deep-learning\\src\\network3.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training mini-batch number {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mcost_ij\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_mb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum_training_batches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     validation_accuracy = np.mean(\n",
      "\u001b[0;32mC:\\Users\\Arnaud\\Anaconda3\\envs\\py27\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Arnaud\\Anaconda3\\envs\\py27\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
    "            validation_data, test_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch number 0\n",
      "Training mini-batch number 1000\n",
      "Training mini-batch number 2000\n",
      "Training mini-batch number 3000\n",
      "Training mini-batch number 4000\n",
      "Epoch 0: validation accuracy 97.74%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 97.67%\n",
      "Training mini-batch number 5000\n",
      "Training mini-batch number 6000\n",
      "Training mini-batch number 7000\n",
      "Training mini-batch number 8000\n",
      "Training mini-batch number 9000\n",
      "Epoch 1: validation accuracy 98.05%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.09%\n",
      "Training mini-batch number 10000\n",
      "Training mini-batch number 11000\n",
      "Training mini-batch number 12000\n",
      "Training mini-batch number 13000\n",
      "Training mini-batch number 14000\n",
      "Epoch 2: validation accuracy 98.18%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.13%\n",
      "Training mini-batch number 15000\n",
      "Training mini-batch number 16000\n",
      "Training mini-batch number 17000\n",
      "Training mini-batch number 18000\n",
      "Training mini-batch number 19000\n",
      "Epoch 3: validation accuracy 98.39%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.41%\n",
      "Training mini-batch number 20000\n",
      "Training mini-batch number 21000\n",
      "Training mini-batch number 22000\n",
      "Training mini-batch number 23000\n",
      "Training mini-batch number 24000\n",
      "Epoch 4: validation accuracy 98.47%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.58%\n",
      "Training mini-batch number 25000\n",
      "Training mini-batch number 26000\n",
      "Training mini-batch number 27000\n",
      "Training mini-batch number 28000\n",
      "Training mini-batch number 29000\n",
      "Epoch 5: validation accuracy 98.34%\n",
      "Training mini-batch number 30000\n",
      "Training mini-batch number 31000\n",
      "Training mini-batch number 32000\n",
      "Training mini-batch number 33000\n",
      "Training mini-batch number 34000\n",
      "Epoch 6: validation accuracy 98.31%\n",
      "Training mini-batch number 35000\n",
      "Training mini-batch number 36000\n",
      "Training mini-batch number 37000\n",
      "Training mini-batch number 38000\n",
      "Training mini-batch number 39000\n",
      "Epoch 7: validation accuracy 98.48%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.58%\n",
      "Training mini-batch number 40000\n",
      "Training mini-batch number 41000\n",
      "Training mini-batch number 42000\n",
      "Training mini-batch number 43000\n",
      "Training mini-batch number 44000\n",
      "Epoch 8: validation accuracy 98.41%\n",
      "Training mini-batch number 45000\n",
      "Training mini-batch number 46000\n",
      "Training mini-batch number 47000\n",
      "Training mini-batch number 48000\n",
      "Training mini-batch number 49000\n",
      "Epoch 9: validation accuracy 98.29%\n",
      "Training mini-batch number 50000\n",
      "Training mini-batch number 51000\n",
      "Training mini-batch number 52000\n",
      "Training mini-batch number 53000\n",
      "Training mini-batch number 54000\n",
      "Epoch 10: validation accuracy 98.65%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.78%\n",
      "Training mini-batch number 55000\n",
      "Training mini-batch number 56000\n",
      "Training mini-batch number 57000\n",
      "Training mini-batch number 58000\n",
      "Training mini-batch number 59000\n",
      "Epoch 11: validation accuracy 98.57%\n",
      "Training mini-batch number 60000\n",
      "Training mini-batch number 61000\n",
      "Training mini-batch number 62000\n",
      "Training mini-batch number 63000\n",
      "Training mini-batch number 64000\n",
      "Epoch 12: validation accuracy 98.77%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.86%\n",
      "Training mini-batch number 65000\n",
      "Training mini-batch number 66000\n",
      "Training mini-batch number 67000\n",
      "Training mini-batch number 68000\n",
      "Training mini-batch number 69000\n",
      "Epoch 13: validation accuracy 98.72%\n",
      "Training mini-batch number 70000\n",
      "Training mini-batch number 71000\n",
      "Training mini-batch number 72000\n",
      "Training mini-batch number 73000\n",
      "Training mini-batch number 74000\n",
      "Epoch 14: validation accuracy 98.75%\n",
      "Training mini-batch number 75000\n",
      "Training mini-batch number 76000\n",
      "Training mini-batch number 77000\n",
      "Training mini-batch number 78000\n",
      "Training mini-batch number 79000\n",
      "Epoch 15: validation accuracy 98.71%\n",
      "Training mini-batch number 80000\n",
      "Training mini-batch number 81000\n",
      "Training mini-batch number 82000\n",
      "Training mini-batch number 83000\n",
      "Training mini-batch number 84000\n",
      "Epoch 16: validation accuracy 98.71%\n",
      "Training mini-batch number 85000\n",
      "Training mini-batch number 86000\n",
      "Training mini-batch number 87000\n",
      "Training mini-batch number 88000\n",
      "Training mini-batch number 89000\n",
      "Epoch 17: validation accuracy 98.67%\n",
      "Training mini-batch number 90000\n",
      "Training mini-batch number 91000\n",
      "Training mini-batch number 92000\n",
      "Training mini-batch number 93000\n",
      "Training mini-batch number 94000\n",
      "Epoch 18: validation accuracy 98.73%\n",
      "Training mini-batch number 95000\n",
      "Training mini-batch number 96000\n",
      "Training mini-batch number 97000\n",
      "Training mini-batch number 98000\n",
      "Training mini-batch number 99000\n",
      "Epoch 19: validation accuracy 98.71%\n",
      "Training mini-batch number 100000\n",
      "Training mini-batch number 101000\n",
      "Training mini-batch number 102000\n",
      "Training mini-batch number 103000\n",
      "Training mini-batch number 104000\n",
      "Epoch 20: validation accuracy 98.80%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.92%\n",
      "Training mini-batch number 105000\n",
      "Training mini-batch number 106000\n",
      "Training mini-batch number 107000\n",
      "Training mini-batch number 108000\n",
      "Training mini-batch number 109000\n",
      "Epoch 21: validation accuracy 98.80%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.95%\n",
      "Training mini-batch number 110000\n",
      "Training mini-batch number 111000\n",
      "Training mini-batch number 112000\n",
      "Training mini-batch number 113000\n",
      "Training mini-batch number 114000\n",
      "Epoch 22: validation accuracy 98.74%\n",
      "Training mini-batch number 115000\n",
      "Training mini-batch number 116000\n",
      "Training mini-batch number 117000\n",
      "Training mini-batch number 118000\n",
      "Training mini-batch number 119000\n",
      "Epoch 23: validation accuracy 98.77%\n",
      "Training mini-batch number 120000\n",
      "Training mini-batch number 121000\n",
      "Training mini-batch number 122000\n",
      "Training mini-batch number 123000\n",
      "Training mini-batch number 124000\n",
      "Epoch 24: validation accuracy 98.90%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 98.88%\n",
      "Training mini-batch number 125000\n",
      "Training mini-batch number 126000\n",
      "Training mini-batch number 127000\n",
      "Training mini-batch number 128000\n",
      "Training mini-batch number 129000\n",
      "Epoch 25: validation accuracy 98.85%\n",
      "Training mini-batch number 130000\n",
      "Training mini-batch number 131000\n",
      "Training mini-batch number 132000\n",
      "Training mini-batch number 133000\n",
      "Training mini-batch number 134000\n",
      "Epoch 26: validation accuracy 98.80%\n",
      "Training mini-batch number 135000\n",
      "Training mini-batch number 136000\n",
      "Training mini-batch number 137000\n",
      "Training mini-batch number 138000\n",
      "Training mini-batch number 139000\n",
      "Epoch 27: validation accuracy 98.84%\n",
      "Training mini-batch number 140000\n",
      "Training mini-batch number 141000\n",
      "Training mini-batch number 142000\n",
      "Training mini-batch number 143000\n",
      "Training mini-batch number 144000\n",
      "Epoch 28: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.18%\n",
      "Training mini-batch number 145000\n",
      "Training mini-batch number 146000\n",
      "Training mini-batch number 147000\n",
      "Training mini-batch number 148000\n",
      "Training mini-batch number 149000\n",
      "Epoch 29: validation accuracy 98.93%\n",
      "Training mini-batch number 150000\n",
      "Training mini-batch number 151000\n",
      "Training mini-batch number 152000\n",
      "Training mini-batch number 153000\n",
      "Training mini-batch number 154000\n",
      "Epoch 30: validation accuracy 98.91%\n",
      "Training mini-batch number 155000\n",
      "Training mini-batch number 156000\n",
      "Training mini-batch number 157000\n",
      "Training mini-batch number 158000\n",
      "Training mini-batch number 159000\n",
      "Epoch 31: validation accuracy 98.90%\n",
      "Training mini-batch number 160000\n",
      "Training mini-batch number 161000\n",
      "Training mini-batch number 162000\n",
      "Training mini-batch number 163000\n",
      "Training mini-batch number 164000\n",
      "Epoch 32: validation accuracy 98.91%\n",
      "Training mini-batch number 165000\n",
      "Training mini-batch number 166000\n",
      "Training mini-batch number 167000\n",
      "Training mini-batch number 168000\n",
      "Training mini-batch number 169000\n",
      "Epoch 33: validation accuracy 98.92%\n",
      "Training mini-batch number 170000\n",
      "Training mini-batch number 171000\n",
      "Training mini-batch number 172000\n",
      "Training mini-batch number 173000\n",
      "Training mini-batch number 174000\n",
      "Epoch 34: validation accuracy 98.93%\n",
      "Training mini-batch number 175000\n",
      "Training mini-batch number 176000\n",
      "Training mini-batch number 177000\n",
      "Training mini-batch number 178000\n",
      "Training mini-batch number 179000\n",
      "Epoch 35: validation accuracy 98.93%\n",
      "Training mini-batch number 180000\n",
      "Training mini-batch number 181000\n",
      "Training mini-batch number 182000\n",
      "Training mini-batch number 183000\n",
      "Training mini-batch number 184000\n",
      "Epoch 36: validation accuracy 98.93%\n",
      "Training mini-batch number 185000\n",
      "Training mini-batch number 186000\n",
      "Training mini-batch number 187000\n",
      "Training mini-batch number 188000\n",
      "Training mini-batch number 189000\n",
      "Epoch 37: validation accuracy 98.93%\n",
      "Training mini-batch number 190000\n",
      "Training mini-batch number 191000\n",
      "Training mini-batch number 192000\n",
      "Training mini-batch number 193000\n",
      "Training mini-batch number 194000\n",
      "Epoch 38: validation accuracy 98.93%\n",
      "Training mini-batch number 195000\n",
      "Training mini-batch number 196000\n",
      "Training mini-batch number 197000\n",
      "Training mini-batch number 198000\n",
      "Training mini-batch number 199000\n",
      "Epoch 39: validation accuracy 98.93%\n",
      "Training mini-batch number 200000\n",
      "Training mini-batch number 201000\n",
      "Training mini-batch number 202000\n",
      "Training mini-batch number 203000\n",
      "Training mini-batch number 204000\n",
      "Epoch 40: validation accuracy 98.93%\n",
      "Training mini-batch number 205000\n",
      "Training mini-batch number 206000\n",
      "Training mini-batch number 207000\n",
      "Training mini-batch number 208000\n",
      "Training mini-batch number 209000\n",
      "Epoch 41: validation accuracy 98.94%\n",
      "Training mini-batch number 210000\n",
      "Training mini-batch number 211000\n",
      "Training mini-batch number 212000\n",
      "Training mini-batch number 213000\n",
      "Training mini-batch number 214000\n",
      "Epoch 42: validation accuracy 98.93%\n",
      "Training mini-batch number 215000\n",
      "Training mini-batch number 216000\n",
      "Training mini-batch number 217000\n",
      "Training mini-batch number 218000\n",
      "Training mini-batch number 219000\n",
      "Epoch 43: validation accuracy 98.94%\n",
      "Training mini-batch number 220000\n",
      "Training mini-batch number 221000\n",
      "Training mini-batch number 222000\n",
      "Training mini-batch number 223000\n",
      "Training mini-batch number 224000\n",
      "Epoch 44: validation accuracy 98.95%\n",
      "Training mini-batch number 225000\n",
      "Training mini-batch number 226000\n",
      "Training mini-batch number 227000\n",
      "Training mini-batch number 228000\n",
      "Training mini-batch number 229000\n",
      "Epoch 45: validation accuracy 98.95%\n",
      "Training mini-batch number 230000\n",
      "Training mini-batch number 231000\n",
      "Training mini-batch number 232000\n",
      "Training mini-batch number 233000\n",
      "Training mini-batch number 234000\n",
      "Epoch 46: validation accuracy 98.95%\n",
      "Training mini-batch number 235000\n",
      "Training mini-batch number 236000\n",
      "Training mini-batch number 237000\n",
      "Training mini-batch number 238000\n",
      "Training mini-batch number 239000\n",
      "Epoch 47: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 240000\n",
      "Training mini-batch number 241000\n",
      "Training mini-batch number 242000\n",
      "Training mini-batch number 243000\n",
      "Training mini-batch number 244000\n",
      "Epoch 48: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 245000\n",
      "Training mini-batch number 246000\n",
      "Training mini-batch number 247000\n",
      "Training mini-batch number 248000\n",
      "Training mini-batch number 249000\n",
      "Epoch 49: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 250000\n",
      "Training mini-batch number 251000\n",
      "Training mini-batch number 252000\n",
      "Training mini-batch number 253000\n",
      "Training mini-batch number 254000\n",
      "Epoch 50: validation accuracy 98.96%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 255000\n",
      "Training mini-batch number 256000\n",
      "Training mini-batch number 257000\n",
      "Training mini-batch number 258000\n",
      "Training mini-batch number 259000\n",
      "Epoch 51: validation accuracy 98.97%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 260000\n",
      "Training mini-batch number 261000\n",
      "Training mini-batch number 262000\n",
      "Training mini-batch number 263000\n",
      "Training mini-batch number 264000\n",
      "Epoch 52: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Training mini-batch number 265000\n",
      "Training mini-batch number 266000\n",
      "Training mini-batch number 267000\n",
      "Training mini-batch number 268000\n",
      "Training mini-batch number 269000\n",
      "Epoch 53: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 270000\n",
      "Training mini-batch number 271000\n",
      "Training mini-batch number 272000\n",
      "Training mini-batch number 273000\n",
      "Training mini-batch number 274000\n",
      "Epoch 54: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 275000\n",
      "Training mini-batch number 276000\n",
      "Training mini-batch number 277000\n",
      "Training mini-batch number 278000\n",
      "Training mini-batch number 279000\n",
      "Epoch 55: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Training mini-batch number 280000\n",
      "Training mini-batch number 281000\n",
      "Training mini-batch number 282000\n",
      "Training mini-batch number 283000\n",
      "Training mini-batch number 284000\n",
      "Epoch 56: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 285000\n",
      "Training mini-batch number 286000\n",
      "Training mini-batch number 287000\n",
      "Training mini-batch number 288000\n",
      "Training mini-batch number 289000\n",
      "Epoch 57: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.20%\n",
      "Training mini-batch number 290000\n",
      "Training mini-batch number 291000\n",
      "Training mini-batch number 292000\n",
      "Training mini-batch number 293000\n",
      "Training mini-batch number 294000\n",
      "Epoch 58: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Training mini-batch number 295000\n",
      "Training mini-batch number 296000\n",
      "Training mini-batch number 297000\n",
      "Training mini-batch number 298000\n",
      "Training mini-batch number 299000\n",
      "Epoch 59: validation accuracy 98.98%\n",
      "This is the best validation accuracy to date.\n",
      "The corresponding test accuracy is 99.19%\n",
      "Finished training network.\n",
      "Best validation accuracy of 98.98% obtained at iteration 299999\n",
      "Corresponding test accuracy of 99.19%\n"
     ]
    }
   ],
   "source": [
    "from network3 import ReLU\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 60, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
